{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import PIL\n",
    "from PIL import ImageFont\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "# import torch.onnx\n",
    "\n",
    "from relaynet_pytorch.relay_net import ReLayNet\n",
    "from relaynet_pytorch.data_utils import get_imdb_data\n",
    "from helper import * # import helper functions\n",
    "\n",
    "# from networks.relay_net import ReLayNet\n",
    "# from networks.data_utils import get_imdb_data\n",
    "\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# For reading in datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OP of ReLayNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relay_out(test_data):\n",
    "    '''\n",
    "    output of relaynet - takes test data in form (1,1,height, width)\n",
    "    '''\n",
    "    out = relaynet_model(Variable(torch.cuda.FloatTensor(test_data)))\n",
    "    out = F.softmax(out,dim=1)\n",
    "    max_val, idx = torch.max(out,1) # torch.max(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor)\n",
    "    return max_val, idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coloured Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEG_LABELS_LIST = [\n",
    "    {\"id\": -1, \"name\": \"void\", \"rgb_values\": [0, 0, 0]},\n",
    "    {\"id\": 0, \"name\": \"Region above the retina (RaR)\", \"rgb_values\": [128, 0, 0]}, # dark red\n",
    "    {\"id\": 1, \"name\": \"ILM: Inner limiting membrane\", \"rgb_values\": [0, 128, 0]}, # green\n",
    "    {\"id\": 2, \"name\": \"NFL-IPL: Nerve fiber ending to Inner plexiform layer\", \"rgb_values\": [128, 128, 0]}, # weird green\n",
    "    {\"id\": 3, \"name\": \"INL: Inner Nuclear layer\", \"rgb_values\": [0, 0, 128]}, # dark blue\n",
    "    {\"id\": 4, \"name\": \"OPL: Outer plexiform layer\", \"rgb_values\": [128, 0, 128]}, # purple\n",
    "    {\"id\": 5, \"name\": \"ONL-ISM: Outer Nuclear layer to Inner segment myeloid\", \"rgb_values\": [0, 128, 128]},\n",
    "    {\"id\": 6, \"name\": \"ISE: Inner segment ellipsoid\", \"rgb_values\": [128, 128, 128]},\n",
    "    {\"id\": 7, \"name\": \"OS-RPE: Outer segment to Retinal pigment epithelium\", \"rgb_values\": [64, 0, 0]},\n",
    "    {\"id\": 8, \"name\": \"Region below RPE (RbR)\", \"rgb_values\": [192, 0, 0]},\n",
    "    {\"id\": 9, \"name\": \"Fluid region\", \"rgb_values\": [64, 128, 0]}\n",
    "    ];\n",
    "    \n",
    "    \n",
    "# SEG_LABELS_LIST = [\n",
    "# #     {\"id\": -1, \"name\": \"void\", \"rgb_values\": [0, 0, 0]},\n",
    "#     {\"id\": 0, \"name\": \"void\", \"rgb_values\": [0, 0, 0]}, # black\n",
    "#     {\"id\": 1, \"name\": \"Myocardium\", \"rgb_values\": [255,0,0]}, # red\n",
    "#     {\"id\": 2, \"name\": \"Endocardium\", \"rgb_values\": [0, 0, 255]}, # blue\n",
    "#     {\"id\": 3, \"name\": \"Fibrosis\", \"rgb_values\": [177,10,255]}, # purple\n",
    "#     {\"id\": 4, \"name\": \"Fat\", \"rgb_values\": [0, 255, 0]}, # green\n",
    "#     {\"id\": 5, \"name\": \"Dense Collagen\", \"rgb_values\": [255, 140, 0]}, # orange\n",
    "#     {\"id\": 6, \"name\": \"Loose Collagen\", \"rgb_values\": [255, 255, 0]}, # yellow\n",
    "#     {\"id\": 7, \"name\": \"Smooth Muscle\", \"rgb_values\": [255,0,255]}# magenta/pink\n",
    "# ]; \n",
    "\n",
    "def label_img_to_rgb(label_img):\n",
    "    label_img = np.squeeze(label_img)\n",
    "    labels = np.unique(label_img)\n",
    "    label_infos = [l for l in SEG_LABELS_LIST if l['id'] in labels]\n",
    "\n",
    "    label_img_rgb = np.array([label_img,\n",
    "                              label_img,\n",
    "                              label_img]).transpose(1,2,0)\n",
    "    for l in label_infos:\n",
    "        mask = label_img == l['id']\n",
    "        label_img_rgb[mask] = l['rgb_values']\n",
    "\n",
    "    return label_img_rgb.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image(idxs):\n",
    "    '''\n",
    "    show image file using idxs\n",
    "    '''\n",
    "    idxs = idxs.data.cpu().numpy()\n",
    "    idxs = label_img_to_rgb(idxs)\n",
    "    plt.imshow(idxs)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segment Image Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_seg_image(idxs, nx, ny, i):\n",
    "    '''\n",
    "    show image file using idxs\n",
    "    '''\n",
    "    idxs = idxs.data.cpu().numpy()\n",
    "    idxs = label_img_to_rgb(idxs)\n",
    "    plt.subplot(Nx, Ny, i)  # next plot will be shown in\n",
    "                        # first subplot in Nx x Ny\n",
    "                        # matrix of subplots\n",
    "    plt.axis('off')\n",
    "    plt.imshow(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_segmented_image(data, height, width, left_bound, right_bound, split, Ny, Nx):\n",
    "    # Segments from image\n",
    "    segments = segment_image(seg_test,left_bound,right_bound,split)\n",
    "\n",
    "    for i in range(1,len(segments)+1):\n",
    "        segments[i-1].shape = (1, 1, height ,split)\n",
    "\n",
    "        # Getting ReLayNet max_val, idx classification values\n",
    "        max_val_trans, idx_trans = relay_out(segments[i-1])\n",
    "\n",
    "        # Test image\n",
    "        show_seg_image(idx_trans, Nx, Ny, i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Legend For Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_legend():\n",
    "    import PIL\n",
    "    from PIL import ImageFont\n",
    "    from PIL import Image\n",
    "    from PIL import ImageDraw\n",
    "\n",
    "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/DejaVuSans.ttf\",10)\n",
    "    img=Image.new(\"RGBA\", (300,350),(256,256,256))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    val = 0\n",
    "    for i in range(1,len(SEG_LABELS_LIST)):\n",
    "        item = SEG_LABELS_LIST[i]\n",
    "        name = item['name']\n",
    "        fill = tuple(item['rgb_values'])\n",
    "        draw.text((10,val), name, fill, font=font)\n",
    "        val += 40\n",
    "\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard show image comparison with legend, test image and main image with option to transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_data(data, transpose=False, show_legend=True, show_test=True, show_main=True, show_ground=True, dst_direct = False, name_of_data=False, save=False):\n",
    "    '''\n",
    "    Show data coming into image\n",
    "    '''\n",
    "    # Test Image\n",
    "    test = np.copy(data) # Copy so it doesn't alter init dimensions of data\n",
    "    \n",
    "    height, width = test.shape\n",
    "    test.shape = (1,1,height,width) # Change dimensions of data\n",
    "    \n",
    "    print(test.shape)\n",
    "    \n",
    "    # Main Image\n",
    "    img_test = test\n",
    "    \n",
    "    if transpose:\n",
    "        # Test Image\n",
    "        test = np.transpose(test, (0, 1, 3, 2)) # Transposing - changes rotation of image \n",
    "        # Main Image\n",
    "        img_test = np.transpose(data, (1,0)) # transpose as changes direction of image\n",
    "\n",
    "    # Getting ReLayNet max_val, idx classification values\n",
    "    max_val_trans, idx_trans = relay_out(test)\n",
    "    \n",
    "    # if we're saving the picture\n",
    "    if save:\n",
    "        show_image(idx_trans)\n",
    "        idx_image = idx_trans.data.cpu().numpy()\n",
    "        idx_image = label_img_to_rgb(idx_image)\n",
    "        if transpose:\n",
    "            name_of_data = name_of_data[:-4] + '_transpose.tif'\n",
    "        \n",
    "        save_result_image(idx_image, dst_direct, name_of_data)\n",
    "    else:\n",
    "        # show legend\n",
    "        if show_legend:\n",
    "            show_legend()\n",
    "\n",
    "        # Test image\n",
    "        if show_test:\n",
    "            print(\"Automated Classification Shape:\",idx_trans.shape)\n",
    "            show_image(idx_trans)\n",
    "\n",
    "        if show_ground:\n",
    "            labelled_data = gnd_truth\n",
    "            print(\"Labelled Classification Shape:\",labelled_data.shape)\n",
    "            if transpose:\n",
    "                # Ground Image\n",
    "                labelled_data = np.transpose(gnd_truth, (1,0,2)) # transpose as changes direction of image\n",
    "            show_main_image(labelled_data)\n",
    "            \n",
    "        # Main Image\n",
    "        if show_main:\n",
    "            print(\"Original Image Shape:\",img_test.shape)\n",
    "            show_main_image(img_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Model\n",
    "\n",
    "First Line below removes warnings from ReLayNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout \n",
    "\n",
    "## My adapted code\n",
    "from torch.utils.serialization import load_lua\n",
    "model = cwd + '/models/Exp01/relaynet_epoch20.model'\n",
    "# model = cwd + '/models/RawOCT2/relaynet_epoch99.model'\n",
    "# model = cwd + '/models/Trained_Networks/layered_segments_normal_bs20_epochs200_01.hdf5'\n",
    "# model = cwd + '/models/relaynet_good.model'\n",
    "\n",
    "# load the model\n",
    "relaynet_model = torch.load(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Printing the test data and the weights for the layers out\n",
    "# relaynet_model # architecture of the net\n",
    "# relaynet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list(relaynet_model.encode1.parameters()) # weights on certain layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Printing model weights\n",
    "# w = list(relaynet_model.parameters())\n",
    "# w\n",
    "# for param in relaynet_model.parameters():\n",
    "#   print(param.data)\n",
    "# list(relaynet_model.parameters()) # all weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(torch.__version__)\n",
    "# torch.cuda.FloatTensor(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "used_image = 4\n",
    "# used_image = 'test_image'\n",
    "\n",
    "if used_image == 1:\n",
    "    image_file = '/datasets/ResizedImages'\n",
    "elif used_image == 2:\n",
    "    # No ground truth\n",
    "    image_file = '/datasets/DenoiseImages/DenoisedTrainImages/denoised_5.png'\n",
    "    # Ventricle\n",
    "elif used_image == 3:\n",
    "    image_file = '/datasets/OCTData/pruned/whole_raw_image/con_H1_N01848_LV_1_194.tif'\n",
    "    gnd_truth_image = '/datasets/OCTData/pruned/manual_label/label_H1_N01848_LV_1_194.JPG'\n",
    "elif used_image == 4:\n",
    "    image_file = '/datasets/OCTData/pruned/whole_raw_image/con_H1_N01848_LA_1_272.tif'\n",
    "    gnd_truth_image = '/datasets/OCTData/pruned/manual_label/label_H1_N01848_LA_1_272.JPG'\n",
    "elif used_image == 5:\n",
    "    image_file = '/datasets/con_H1_N01848_LA_1_272_denoised.png'\n",
    "    gnd_truth_image = '/datasets/OCTData/Atrium/H1_N01848_LA_1_272/label_H1_N01848_LA_1_272.JPG'\n",
    "elif used_image == 'test_image':\n",
    "    image_file = '/datasets/test_image.png'\n",
    "\n",
    "# Seeing whether image_file exists\n",
    "print(cwd)\n",
    "raw_image_path = cwd + image_file\n",
    "print(raw_image_path)\n",
    "image = plt.imread(raw_image_path)\n",
    "test_data = image    \n",
    "\n",
    "if used_image == 'test_image':\n",
    "    test_data = test_data[:400,:400, 0]\n",
    "\n",
    "print(test_data.shape)\n",
    "plt.imshow(test_data,cmap = \"gray\")\n",
    "plt.show()\n",
    "\n",
    "if used_image == 3 or used_image == 4 or used_image == 5:\n",
    "    # Seeing whether labelled_image exists\n",
    "    label_image_path = cwd + gnd_truth_image\n",
    "    gnd_truth = plt.imread(label_image_path)\n",
    "    print(gnd_truth.shape)\n",
    "    plt.imshow(gnd_truth)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful sources:\n",
    "\n",
    "* https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "\n",
    "* https://github.com/pytorch/tutorials/issues/78 \n",
    "\n",
    "* https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "\n",
    "* https://www.google.co.uk/search?q=torch+split+image+then+join+image&oq=torch+split+image+then+join+image+&aqs=chrome..69i57.15014j0j4&sourceid=chrome&ie=UTF-8\n",
    "\n",
    "* https://pytorch.org/docs/master/torchvision/transforms.html\n",
    "\n",
    "* https://pytorch.org/tutorials/beginner/data_loading_tutorial.html?highlight=torchvision\n",
    "\n",
    "* https://stackoverflow.com/questions/29434729/torch-resize-tensor\n",
    "\n",
    "* https://pytorch.org/docs/stable/torchvision/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_result_image(src, dst):\n",
    "#     '''\n",
    "#     Save image results for any src directory\n",
    "#     '''\n",
    "#     for file in os.listdir(src):\n",
    "#     #     if count < 2:\n",
    "#         if file.endswith(\".tif\") or file.endswith(\".png\"):\n",
    "#             image_path = os.path.join(src, file)\n",
    "#             image = plt.imread(image_path)\n",
    "#             transposed_image = np.transpose(image, (1,0))\n",
    "\n",
    "#             H,W = image.shape\n",
    "#             if H > 512 or W > 600:\n",
    "#                 print('Cropping_image')\n",
    "#                 print('old_image.shape',image.shape)\n",
    "#                 image = crop_image(image, 0, 600)\n",
    "#                 print(\"new_image.shape\",image.shape)\n",
    "#                 save_image(image, src, file, '.png', 1)\n",
    "#             show_data(image, transpose=False, show_test=False, show_legend=False, show_ground=False)\n",
    "#             show_data(image, transpose=False, dst_direct = dst, name_of_data=file, save=True)\n",
    "#             show_main_image(transposed_image)\n",
    "#             show_data(image, transpose=True, dst_direct = dst, name_of_data=file, save=True)\n",
    "\n",
    "#             ext = file[-4:] \n",
    "#             file = file[:-4]+'_transpose'+ext\n",
    "#             dst_folder = src+'transpose/'\n",
    "#             save_image(transposed_image, dst_folder, file, '.png', 1)\n",
    "#             count += 1\n",
    "            \n",
    "# raw_src = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/whole_raw_image/'\n",
    "# raw_dst = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/results/raw/'\n",
    "# # get_result_image(raw_src, raw_dst) # results for raw src images\n",
    "\n",
    "# brush_denoised_src = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/brushlet_denoised/'\n",
    "# brush_denoised_dst = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/results/brushlet_denoised/'\n",
    "# # get_result_image(brush_denoised_src, brush_denoised_dst) # results for brush denoised images\n",
    "\n",
    "# brush_enhanced_src = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/brushlet_enhanced/'\n",
    "# brush_enhanced_dst = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/results/brushlet_enhanced/'\n",
    "# # get_result_image(brush_enhanced_src, brush_enhanced_dst) # results for brush enhanced images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw_path = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/results/raw/con_H2_N02047_LA_1_257_result_raw.png'\n",
    "# raw_image = plt.imread(raw_path)\n",
    "# show_main_image(raw_image)\n",
    "# denoised_path = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/results/brushlet_denoised/con_H2_N02047_LA_1_257_result_raw.png'\n",
    "# denoised_image = plt.imread(denoised_path)\n",
    "# show_main_image(denoised_image)\n",
    "# enhanced_path = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/results/brushlet_enhanced/con_H2_N02047_LA_1_257_result_raw.png'\n",
    "# enhanced_image = plt.imread(enhanced_path)\n",
    "# show_main_image(enhanced_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Model on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Size Segmentation\n",
    "\n",
    "Helpful Source: https://www.southampton.ac.uk/~fangohr/teaching/python/book/html/15-visualising-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Settings for segmentation\n",
    "seg_test = np.squeeze(test_data.T)\n",
    "height, width = seg_test.shape\n",
    "left_bound = 0\n",
    "right_bound = width\n",
    "split = m_of_e(64) # must be mutiples of 8 \n",
    "Ny = width/split\n",
    "Nx = 1\n",
    "\n",
    "print(\"Split:\",split)\n",
    "\n",
    "# Show Segmentations\n",
    "get_segmented_image(seg_test, height, width, left_bound, right_bound, split, Ny, Nx)\n",
    "\n",
    "# Show other images\n",
    "show_data(test_data, show_legend=False, transpose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose vs Not Transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show_data(test_data, show_legend=False, transpose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not Transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show_data(test_data, show_legend = False, transpose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = np.zeros((512,600)) # create numpy array of size 512 x 600\n",
    "# data = np.array([[11, 22, 33, 44, 55],[2,3,4,5,6],[10,20,30,40,50]])\n",
    "# print(data[:,0])\n",
    "# print(type(test_data))\n",
    "# print(test_data.shape)\n",
    "# print(test_data.dtype)\n",
    "# new_test_data = np.zeros((512,600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Dummy Input\n",
    "# # Input is organised [No., Channel, Width, Height] - [1,1,64,512]\n",
    "# # Float tensor because weights are float Tensors\n",
    "\n",
    "# dummy_input = Variable(torch.cuda.FloatTensor(1,1,64,512)) # has to be (1,1,...) because the first is no. therefore can't plot 2d image on same plot.\n",
    "# # print(dummy_input)\n",
    "# # Getting ReLayNet max_val, idx classification values\n",
    "# max_val_trans, idx_trans = relay_out(dummy_input)\n",
    "\n",
    "# # Test image\n",
    "# show_image(idx_trans)\n",
    "\n",
    "# # new_test = np.transpose(new_test, (0, 1, 3, 2)) # Transposing changes rotation of image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Model\n",
    "##### Date:  13/07/2018 \n",
    "Can't export model as MaxPool2d with index output is not supported in ONNX: https://discuss.pytorch.org/t/problems-converting-pytorch-model-into-onnx/12192/3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removed code from batchnorm.py for all references to track_running_stats - see comments in the code\n",
    "\n",
    "# relaynet_model.eval()\n",
    "# dummy_input = Variable(torch.cuda.FloatTensor(1,1,600,64)) # has to be (1,1,...) because the first is no. therefore can't plot 2d image on same plot.\n",
    "# torch.onnx.export(relaynet_model, dummy_input, \"model.onnx\", verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
