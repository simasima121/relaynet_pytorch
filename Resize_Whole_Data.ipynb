{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pprint\n",
    "import cv2\n",
    "from scipy.misc import imsave\n",
    "from helper import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_rgb(color):\n",
    "    r,g,b = color\n",
    "    return (int(r),int(g),int(b))\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/9694165/convert-rgb-color-to-english-color-name-like-green-with-python\n",
    "def closest_colour(requested_colour):\n",
    "    min_colours = {}\n",
    "    for key, name in wb.css3_hex_to_names.items():\n",
    "        r_c, g_c, b_c = wb.hex_to_rgb(key)\n",
    "        rd = (r_c - requested_colour[0]) ** 2\n",
    "        gd = (g_c - requested_colour[1]) ** 2\n",
    "        bd = (b_c - requested_colour[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]\n",
    "\n",
    "def get_colour_name(requested_colour):\n",
    "    try:\n",
    "        closest_name = actual_name = wb.rgb_to_name(requested_colour)\n",
    "    except ValueError:\n",
    "        closest_name = closest_colour(requested_colour)\n",
    "        actual_name = None\n",
    "    return actual_name, closest_name\n",
    "\n",
    "# Source Source: https://stackoverflow.com/questions/45043617/count-the-number-of-objects-of-different-colors-in-an-image-in-python\n",
    "def find_colors(file_name):\n",
    "    from skimage import io, morphology, measure\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    img = io.imread(file_name)\n",
    "\n",
    "    rows, cols, bands = img.shape\n",
    "    X = img.reshape(rows*cols, bands)\n",
    "\n",
    "\n",
    "    kmeans = KMeans(n_clusters=6, random_state=0).fit(X)\n",
    "    labels = kmeans.labels_.reshape(rows, cols)\n",
    "\n",
    "    for i in np.unique(labels):\n",
    "        blobs = np.int_(morphology.binary_opening(labels == i))\n",
    "        color = np.around(kmeans.cluster_centers_[i])\n",
    "        actual_name, closest_name = get_colour_name(to_rgb(color))\n",
    "        count = len(np.unique(measure.label(blobs))) - 1\n",
    "        \n",
    "        print('Color: {}, RGB: {}  >>  Objects: {}'.format(closest_name,color, count))\n",
    "        \n",
    "def pixel_colors(file_name):\n",
    "    '''\n",
    "    Creating a dictionary of colours to see what colors are in images.\n",
    "    '''\n",
    "    from skimage import io\n",
    "    if type(file_name) == str:\n",
    "        img = io.imread(file_name)\n",
    "    else:\n",
    "        img = file_name\n",
    "    \n",
    "    new_img = np.copy(img)\n",
    "    rows, cols, bands = new_img.shape\n",
    "    \n",
    "    dict_of_colours = {}\n",
    "    for row in range(150,350):\n",
    "        if row % 25 == 0:\n",
    "            print(row)\n",
    "        for col in range(0,50):\n",
    "            pixel_color = new_img[row][col]\n",
    "            actual, close = get_colour_name(pixel_color)\n",
    "            if actual != None:\n",
    "                if actual in dict_of_colours:\n",
    "                    dict_of_colours[actual] += 1\n",
    "                else:\n",
    "                    dict_of_colours[actual] = 1\n",
    "                list_of_colors.add(actual)\n",
    "            else:\n",
    "                if close in dict_of_colours:\n",
    "                    dict_of_colours[close] += 1\n",
    "                else:\n",
    "                    dict_of_colours[close] = 1\n",
    "\n",
    "    return dict_of_colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import webcolors as wb\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.color import rgb2lab, deltaE_cie76\n",
    "from PIL import Image\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/44428315/similar-color-detection-in-python\n",
    "\n",
    "# Blurring image \n",
    "def blur_image(img, b):\n",
    "    if b == \"average\":\n",
    "        kernel = np.ones((3,6),np.float32)/25\n",
    "        blurred = cv2.filter2D(img,-1,kernel)\n",
    "    elif b == \"gaussian\":\n",
    "    # Gaussian Blur\n",
    "        blur=cv2.GaussianBlur(img,(13,13),0)\n",
    "        blurred=cv2.cvtColor(blur,cv2.COLOR_BGR2HSV)\n",
    "    elif b == \"bilateral\":\n",
    "    # Bilaterial Filter\n",
    "        blur=cv2.bilateralFilter(img,4,25,25)\n",
    "        blurred=cv2.cvtColor(blur,cv2.COLOR_BGR2HSV)\n",
    "    return blurred\n",
    "\n",
    "def turn_array(rgb):\n",
    "    '''\n",
    "    turn rgb into np.array\n",
    "    '''\n",
    "    return np.uint8(np.asarray([[rgb]]))\n",
    "\n",
    "def turn_rgb_2_lab(color, lab):\n",
    "    '''\n",
    "    Convert RGB to CIE 1976 L*a*b*\n",
    "    '''\n",
    "    return deltaE_cie76(rgb2lab(color),lab)\n",
    "\n",
    "def rgb_to_id(rgb, threshold, color, ids, lab):\n",
    "    '''\n",
    "    Convert rgb to id\n",
    "    '''\n",
    "#     print(get_colour_name(color), color, ids)\n",
    "    color_3d = turn_array(color)\n",
    "    dE_color = turn_rgb_2_lab(color_3d, lab)\n",
    "    rgb[dE_color < threshold] = ids\n",
    "#     rgb[dE_color < threshold] = color\n",
    "\n",
    "    return rgb\n",
    "\n",
    "def ref_colour(rgb):\n",
    "# def ref_colour():\n",
    "    '''\n",
    "    Finding colours within a range of the colour input\n",
    "    input = pixel\n",
    "    '''\n",
    "    rgb = io.imread('https://i.stack.imgur.com/npnrv.png') # to show where the images overlap\n",
    "    new_rgb = np.copy(rgb)\n",
    "    \n",
    "    lab = rgb2lab(new_rgb)\n",
    "    \n",
    "    threshold = 15  \n",
    "    \n",
    "    # Black = Grey \n",
    "    black = [0, 0, 0]\n",
    "    dimgrey = [105, 105, 105]\n",
    "    darkslategrey = [47, 79, 79]\n",
    "    lightgrey = [211, 211, 211]\n",
    "    gainsboro = [220, 220, 220]\n",
    "    grey = [128, 128, 128]\n",
    "    lightslategrey = [119, 136, 153]\n",
    "    darkgrey = [169, 169, 169]\n",
    "    \n",
    "    # NOTE: USED TO BE -1 BUT CHANGED AS VALUE NEEDED FOR CROSS ENTROPY - CAN'T HAVE 0\n",
    "    rgb_to_id(new_rgb, threshold, black, 0, lab)\n",
    "    rgb_to_id(new_rgb, threshold, dimgrey, 0, lab)\n",
    "    rgb_to_id(new_rgb, threshold, darkslategrey, 0, lab)\n",
    "    rgb_to_id(new_rgb, threshold, lightgrey, 0, lab)\n",
    "    rgb_to_id(new_rgb, threshold, gainsboro, 0, lab)\n",
    "    rgb_to_id(new_rgb, threshold, grey, 0, lab)\n",
    "    rgb_to_id(new_rgb, threshold, lightslategrey, 0, lab)\n",
    "    rgb_to_id(new_rgb, threshold, darkgrey, 0, lab)\n",
    "    \n",
    "    # Red = OrangeRed\n",
    "    red = [255,0,0]\n",
    "    orangered = [255, 69, 0]\n",
    "    firebrick = [181,17,17]\n",
    "    \n",
    "    rgb_to_id(new_rgb, threshold, red, 1, lab)\n",
    "    rgb_to_id(new_rgb, threshold, orangered, 1, lab)\n",
    "    rgb_to_id(new_rgb, threshold, firebrick, 1, lab)\n",
    "    \n",
    "    # Blue\n",
    "    blue = [0, 0, 255]\n",
    "    darkslateblue = [72, 61, 139]\n",
    "    midnightblue = [25, 25, 112]\n",
    "    mediumblue = [0, 0, 205]\n",
    "    \n",
    "    rgb_to_id(new_rgb, threshold, blue, 2, lab)\n",
    "    rgb_to_id(new_rgb, threshold, darkslateblue, 2, lab)\n",
    "    rgb_to_id(new_rgb, threshold, midnightblue, 2, lab)\n",
    "    rgb_to_id(new_rgb, threshold, mediumblue, 2, lab)\n",
    "    \n",
    "    # Purple = Dark Violet = Medium Purple = Darkorchid\n",
    "    purple = [128,0,128]\n",
    "    darkviolet = [177,10,255]\n",
    "    mediumpurple = [147, 112, 219]\n",
    "    darkorchid = [153, 50, 204]\n",
    "    \n",
    "    rgb_to_id(new_rgb, threshold, purple, 3, lab)\n",
    "    rgb_to_id(new_rgb, threshold, darkviolet, 3, lab)\n",
    "    rgb_to_id(new_rgb, threshold, mediumpurple, 3, lab)\n",
    "    rgb_to_id(new_rgb, threshold, darkorchid, 3, lab)\n",
    "    \n",
    "    # Green is same as Lime and limegreen\n",
    "    green = [0,128,0]\n",
    "    lime = [0,255,0]\n",
    "    limegreen = [50, 205, 50]\n",
    "    \n",
    "    rgb_to_id(new_rgb, threshold, green, 4, lab)\n",
    "    rgb_to_id(new_rgb, threshold, lime, 4, lab)\n",
    "    rgb_to_id(new_rgb, threshold, limegreen, 4, lab)\n",
    "    \n",
    "    # Orange is same as dark orange\n",
    "    orange = [255, 165, 0]\n",
    "    darkorange = [255, 140, 0]\n",
    "    chocolate = [180,101,24]\n",
    "    \n",
    "    rgb_to_id(new_rgb, threshold, orange, 5, lab)\n",
    "    rgb_to_id(new_rgb, threshold, darkorange, 5, lab)\n",
    "    rgb_to_id(new_rgb, threshold, chocolate, 5, lab)\n",
    "    \n",
    "    # Yellow = Gold\n",
    "    yellow = [255,255,0]\n",
    "    gold = [255, 215, 0]\n",
    "    goldenrod = [218, 165, 32]\n",
    "    goldenrod2 = [183,178,36]\n",
    "    darkgoldenrod = [184, 134, 11]\n",
    "    \n",
    "    rgb_to_id(new_rgb, threshold, yellow, 6, lab)\n",
    "    rgb_to_id(new_rgb, threshold, gold, 6, lab)\n",
    "    rgb_to_id(new_rgb, threshold, goldenrod, 6, lab)\n",
    "    rgb_to_id(new_rgb, threshold, goldenrod2, 6, lab)\n",
    "    rgb_to_id(new_rgb, threshold, darkgoldenrod, 6, lab)\n",
    "    \n",
    "    # Magenta/Fuschia\n",
    "    magenta = [255,0,255]\n",
    "    darkmagenta = [139, 0, 139]\n",
    "    \n",
    "    magenta_threshold = 20\n",
    "    \n",
    "    rgb_to_id(new_rgb, magenta_threshold, magenta, 7, lab)\n",
    "    rgb_to_id(new_rgb, magenta_threshold, darkmagenta, 7, lab)\n",
    "    \n",
    "#     new_grey = new_rgb\n",
    "    new_grey = cv2.cvtColor( new_rgb, cv2.COLOR_RGB2GRAY ) # convert image to grayscale\n",
    "    \n",
    "    return new_grey\n",
    "# rgb = ref_colour()\n",
    "# plt.imshow(rgb)\n",
    "\n",
    "def convert_to_id_image(image):\n",
    "    '''\n",
    "    convert rgb images to id\n",
    "    '''\n",
    "    returned_grey_image = ref_colour(image)\n",
    "    rows, cols = returned_grey_image.shape\n",
    "    g_y = np.copy(returned_grey_image)\n",
    "    for x in range(0, rows):\n",
    "        for j in range(0,cols):\n",
    "#             if returned_grey_image[x][j] > 7: # Setting values in the array to void if they're not in labels\n",
    "#                 returned_grey_image[x][j] = -1 # this created issue with cross_entropy\n",
    "            if returned_grey_image[x][j] > 7: # Setting values in the array to void if they're not in labels\n",
    "                g_y[x][j] = 0\n",
    "    print(np.unique(g_y))\n",
    "    return g_y\n",
    "\n",
    "def convert_to_rgb_image(id_image):\n",
    "    '''\n",
    "    Convert id back to rgb \n",
    "    '''\n",
    "    rows, cols = id_image.shape\n",
    "\n",
    "    black = [0, 0, 0]# id = 0\n",
    "    red = [255,0,0] # id = 1\n",
    "    blue = [0, 0, 255] # id = 2\n",
    "    darkviolet = [177,10,255] # id = 3\n",
    "    lime = [0,255,0] # id = 4\n",
    "    darkorange = [255, 140, 0] # id = 5\n",
    "    yellow = [255, 255, 0] # id = 6\n",
    "    magenta = [255,0,255] # id = 7\n",
    "    \n",
    "    colors = [ black, red, blue, darkviolet, lime, darkorange, yellow, magenta]\n",
    "    new_image = np.zeros((rows,cols,3))\n",
    "    for x in range(0, rows):\n",
    "        for j in range(0,cols):\n",
    "            pixel_value = int(id_image[x][j])\n",
    "            if pixel_value > 7: # Setting values in the array to black if they're not in labels\n",
    "                print(pixel_value)\n",
    "                new_image[x][j] = black\n",
    "            else:\n",
    "                new_image[x][j] = colors[pixel_value] # setting id to colours - values between 1-7\n",
    "    return new_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying Weighting algorithm to an image\n",
    "value = 1\n",
    "def weighting_algo(id_image):\n",
    "    '''\n",
    "    Creating weighting of an image\n",
    "    '''\n",
    "    image = id_image\n",
    "    x,y = image.shape\n",
    "    weighted_image = np.zeros((x,y))\n",
    "    for j in range(x):\n",
    "        for k in range(y):\n",
    "            # NOTE: did weights based on bold from legend\n",
    "            if(image[j][k]==1): # 1 red - myocardium\n",
    "                 w2 = 10 * value \n",
    "            elif(image[j][k] == 2): # blue - endocardium\n",
    "                 w2 = 10 * value\n",
    "            elif(image[j][k]== 3): # purple - fibrosis\n",
    "                 w2 = 5 * value\n",
    "            elif(image[j][k] == 4): # green - fat\n",
    "                 w2 = 10 * value\n",
    "            elif(image[j][k]== 5): # orange - dense collagen\n",
    "                 w2 = 5 * value\n",
    "            elif(image[j][k]== 6): # yellow - loose collagen\n",
    "                 w2 = 5 * value\n",
    "            elif(image[j][k]== 7):\n",
    "                 w2 = 5 * value # magenta - smooth muscle\n",
    "            else:\n",
    "                 w2 = 0\n",
    "            if(j!=0 and j!=x-1):\n",
    "                next_pix = image[j+1][k]\n",
    "                prev_pix = image[j-1][k]\n",
    "                # Taking the derivative of the pixels\n",
    "                if(np.absolute((next_pix-prev_pix))>0 and w2!=0):\n",
    "                    w1 = 10  \n",
    "                else:\n",
    "                    w1 = 0\n",
    "            else:\n",
    "                w1 = 0\n",
    "            w = 1 + w1 + w2\n",
    "            weighted_image[j][k] = w\n",
    "    return weighted_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 black\n",
    "# 1 red - myocardium\n",
    "# 2 blue - endocardium\n",
    "# 3 purple - fibrosis\n",
    "# 4 green - fat\n",
    "# 5 orange - dense collagen\n",
    "# 6 yellow - loose collagen\n",
    "# 7 magenta - smooth muscle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting the directories\n",
    "import os\n",
    "\n",
    "\n",
    "wanted_folder = 'alldata/'\n",
    "# wanted_folder = 'pruned/'\n",
    "# wanted_folder = 'Atrium/'\n",
    "# wanted_folder = 'Ventricle/'\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cwd = cwd + '/datasets/OCTData/'+wanted_folder\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whole_raw_image_folder = cwd + 'whole_raw_image/'\n",
    "brushlet_enhanced_folder = cwd + 'brushlet_enhanced/'\n",
    "brushlet_denoised_folder = cwd + 'brushlet_denoised/'\n",
    "manual_label_folder = cwd + 'manual_label/'\n",
    "all_labels_folder = cwd + 'all_labels/'\n",
    "sim_labels_folder = cwd + 'my_labels/'\n",
    "# corrected_labels_folder = cwd + 'labels_corrected/'\n",
    "corrected_labels_folder = cwd + 'png_labels_method/'\n",
    "\n",
    "list_of_folders = [whole_raw_image_folder, brushlet_denoised_folder, brushlet_enhanced_folder, manual_label_folder, all_labels_folder, sim_labels_folder, corrected_labels_folder]\n",
    "print(len(list_of_folders))\n",
    "def list_all_files(directory):\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    all_labels_files = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "    all_labels_files.sort()\n",
    "    return all_labels_files\n",
    "\n",
    "files_list = []\n",
    "for folders in list_of_folders:\n",
    "    files_list.append(list_all_files(folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating list of file names\n",
    "new_file_list = []\n",
    "\n",
    "for i in files_list[0]:\n",
    "    if i[:4] == 'con_':\n",
    "        string = i[4:]\n",
    "        file_name = string[:19].replace('.','')\n",
    "    new_file_list.append(file_name)\n",
    "\n",
    "new_file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing Unwanted Files\n",
    "unwanted_files = []\n",
    "\n",
    "# anon_count = 0\n",
    "# for count, i in enumerate(new_file_list):\n",
    "#     if i == 'H3_N02186_RV_1_270' or i == 'H3_N02186_RV_1_400' or i == 'H4_N03210_LV_1_400' or i == 'H4_N03210_RV_1_390':\n",
    "#         print(count,i)\n",
    "#         unwanted_files.append(count)\n",
    "#     elif i == 'H4_N03210_RV_1_400' or i == 'H5_N03290_LV_1_420' or i == 'H6_N03320_LVS_1_455':\n",
    "#         print(count,i)\n",
    "#         unwanted_files.append(count)\n",
    "# #     Second set of unwanted files if not clear segments\n",
    "#     elif i == 'H1_N01848_LV_1_194' or i == 'H1_N01848_LV_1_300' or i == 'H3_N02186_LVS_1_265':\n",
    "#         print(count,i)\n",
    "#         unwanted_files.append(count)\n",
    "#     elif i == 'H6_N03320_LV_1_404' or i == 'H6_N03320_LVS_1_455':\n",
    "#         print(count,i)\n",
    "#         unwanted_files.append(count)\n",
    "#     elif i == 'H1_N01848_LV_1_194' or i == 'H1_N01848_LV_1_300' or i == 'H2_N02047_LVS_1_400' or i == 'H2_N02047_LVS_1_420' or i == 'H3_N02186_LVS_1_265' or i == 'H4_N03210_RV_1_390' or i == 'H4_N03210_RV_1_400' or i == 'H5_N03290_LV_1_420' or i == 'H6_N03320_LV_1_404' or i == 'H6_N03320_LVS_1_455' or i == 'H6_N03320_RA_1_420' or i == 'H8_N03585_RA_1_345':\n",
    "#         print(count,i)\n",
    "#         unwanted_files.append(count)\n",
    "# #     elif i[11] == 'V':\n",
    "# #         print(count,i)\n",
    "# #         unwanted_files.append(count)\n",
    "print(unwanted_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(unwanted_files))\n",
    "print(len(new_file_list))\n",
    "print(len(new_file_list)-len(unwanted_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Image Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def segment_image_multiple(image, left_bound, right_bound, split):\n",
    "    '''\n",
    "    Segment image at intervals of half of split to have more training data\n",
    "    \n",
    "    Segment image by input of image, left bound and right bound, and split int \n",
    "    '''\n",
    "    list_of_images = []\n",
    "    bounds = right_bound - left_bound\n",
    "    quot, rem = divmod(bounds, split)\n",
    "#     print(quot, rem)\n",
    "    ranged = np.arange(0,quot,0.7)\n",
    "    ranged = ranged[:-1] # change size of range to ensure all have same length\n",
    "    for i in ranged:\n",
    "#         print(i*split, (i+1)*split)\n",
    "        if len(image.shape) == 2:\n",
    "            cropped_image = crop_image(image, int(i*split), int((i+1) * split))\n",
    "            list_of_images.append(cropped_image)\n",
    "        elif len(image.shape) == 3:\n",
    "            cropped_image = crop_image(image, int(i*split), int((i+1) * split), False)\n",
    "            list_of_images.append(cropped_image)\n",
    "#         print(cropped_image.shape)\n",
    "    return list_of_images\n",
    "\n",
    "whole_raw_1 = plt.imread(whole_raw_image_folder+files_list[0][0])\n",
    "segmented_whole = segment_image_multiple(whole_raw_1, 0, 600, 64)\n",
    "\n",
    "for i in segmented_whole:\n",
    "    plt.imshow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving images\n",
    "def crop_and_save_raw(image, src_direct, name):\n",
    "    dst_drc = src_direct + 'Train/'\n",
    "\n",
    "    # Crop all images\n",
    "    if len(image.shape) == 2:\n",
    "        height, width = image.shape\n",
    "        if width > 600:\n",
    "            image = crop_image(image, 0, 600) # Crop all images at 512,600\n",
    "    elif len(image.shape) == 3:\n",
    "        height, width, colour = image.shape\n",
    "        if width > 600:\n",
    "            image = crop_image(image, 0, 600, colour) # Crop all images at 512,600\n",
    "#     plt.imshow(image)\n",
    "#     print(image.shape)\n",
    "#     segmented_images = segment_image(image, 0, 600, 64)\n",
    "    segmented_images = segment_image_multiple(image, 0, 600, 64)\n",
    "#     print(len(segmented_images))\n",
    "#     fig, axes = plt.subplots(nrows=1, ncols=len(segmented_images), figsize=(9,20))\n",
    "#     for i, ax in enumerate(axes):\n",
    "#         ax.imshow(segmented_images[i])\n",
    "#         ax.set_title(i)\n",
    "#     plt.show()\n",
    "    for i in range(len(segmented_images)):\n",
    "        image_name = dst_drc+name+'_'+str(i+1)+'.png'\n",
    "        cur_image = segmented_images[i]\n",
    "        imsave(image_name, cur_image)\n",
    "#     return image_name\n",
    "\n",
    "# Saving labels and weights\n",
    "def crop_and_save_label(label, src_direct, name):\n",
    "    id_dst_drc = src_direct + 'Train/segmented_ids/'\n",
    "    weight_dst_drc = src_direct + 'Train/weights/'\n",
    "    height, width = label.shape\n",
    "    \n",
    "    label[440:,:] = 0\n",
    "    \n",
    "    if width > 600:\n",
    "        label = crop_image(label, 0, 600)\n",
    "    if height != 512:\n",
    "        amount = 512 - height\n",
    "        id_full = np.zeros((amount,600))\n",
    "        label = np.concatenate((label, id_full))\n",
    "    \n",
    "    rgb_image = convert_to_rgb_image(label) \n",
    "    plt.imshow(rgb_image)\n",
    "#     segmented_labels = segment_image(label, 0, 600, 64)\n",
    "    segmented_labels = segment_image_multiple(label, 0, 600, 64)\n",
    "    \n",
    "    for i in range(len(segmented_labels)):\n",
    "        id_name = id_dst_drc+'id_'+name+'_'+str(i+1)+'.npy'\n",
    "        weight_name = weight_dst_drc+'weight_'+name+'_'+str(i+1)+'.npy'\n",
    "        \n",
    "        cur_label = segmented_labels[i]\n",
    "        \n",
    "        # convert image_id into weighted image \n",
    "        weighted_image = weighting_algo(cur_label)\n",
    "        \n",
    "        # Saving labels and weights\n",
    "        np.save(id_name,np.array(cur_label))\n",
    "        np.save(weight_name,np.array(weighted_image))\n",
    "\n",
    "    return name\n",
    "\n",
    "# Saving images\n",
    "def save_label(image, src_direct, name):\n",
    "    dst_drc = src_direct\n",
    "    \n",
    "    # Crop all images\n",
    "    if len(image.shape) == 2:\n",
    "        height, width = image.shape\n",
    "        if width > 600:\n",
    "            image = crop_image(image, 0, 600) # Crop all images at 512,600\n",
    "    elif len(image.shape) == 3:\n",
    "        height, width, colour = image.shape\n",
    "        if width > 600:\n",
    "            image = crop_image(image, 0, 600, colour) # Crop all images at 512,600\n",
    "    id_image = convert_to_id_image(image)\n",
    "    image_name = dst_drc+\"label_\"+name+'.png'\n",
    "    imsave(image_name, id_image)\n",
    "#     rgb_image = convert_to_rgb_image(id_image)\n",
    "#     plt.imshow(id_image)\n",
    "#     plt.imshow(rgb_image)\n",
    "#     print(id_image.shape)\n",
    "#     print(np.unique(id_image))\n",
    "#     return image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_files(mydir, ext):\n",
    "    filelist = [ f for f in os.listdir(mydir) if f.endswith(ext) ]\n",
    "    for f in filelist:\n",
    "        os.remove(os.path.join(mydir, f))\n",
    "remove = False\n",
    "if remove:\n",
    "    whole_raw_image_folder_rem = cwd + 'whole_raw_image/Train/'\n",
    "    brushlet_enhanced_folder_rem = cwd + 'brushlet_enhanced/Train/'\n",
    "    brushlet_denoised_folder_rem = cwd + 'brushlet_denoised/Train/'\n",
    "    manual_label_folder_rem = cwd + 'manual_label/Train/'\n",
    "    all_labels_folder_ids_rem = cwd + 'all_labels/Train/segmented_ids/'\n",
    "    all_labels_folder_weights_rem = cwd + 'all_labels/Train/weights/'\n",
    "    sim_labels_folder_ids_rem = cwd + 'my_labels/Train/segmented_ids/'\n",
    "    sim_labels_folder_weights_rem = cwd + 'my_labels/Train/weights/'\n",
    "    corrected_labels_folder_ids_rem = cwd + 'png_labels_method/Train/segmented_ids/'\n",
    "    corrected_labels_folder_weights_rem = cwd + 'png_labels_method/Train/weights/'\n",
    "    \n",
    "    remove_files(whole_raw_image_folder_rem, '.png')\n",
    "    remove_files(brushlet_enhanced_folder_rem, '.png')\n",
    "    remove_files(brushlet_denoised_folder_rem, '.png')\n",
    "    remove_files(manual_label_folder_rem, '.png')\n",
    "    remove_files(all_labels_folder_ids_rem, '.npy')\n",
    "    remove_files(all_labels_folder_weights_rem, '.npy')\n",
    "    remove_files(sim_labels_folder_ids_rem, '.npy')\n",
    "    remove_files(sim_labels_folder_weights_rem, '.npy')\n",
    "    remove_files(corrected_labels_folder_ids_rem, '.npy')\n",
    "    remove_files(corrected_labels_folder_weights_rem, '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The values of the conversion by Elsa\n",
    "values = [0.0, 0.007843138, 0.011764706, 0.015686275, 0.019607844, 0.023529412, 0.02745098]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extensions\n",
    "raw_ext = '.tif'\n",
    "label_ext = '.JPG'\n",
    "\n",
    "whole_raw_ext = '.tif'\n",
    "man_lab_ext = '.JPG'\n",
    "everything_else_ext = '.png'\n",
    "\n",
    "# Loop through images to determine whether their weights and they are looking correct\n",
    "l_values = set()\n",
    "for i in range(len(files_list[0])):\n",
    "# for i in range(20, len(files_list[0])):\n",
    "    # choosing files I don't like\n",
    "    if i not in unwanted_files:\n",
    "        print(i)\n",
    "        whole_raw = plt.imread(whole_raw_image_folder+files_list[0][i]) # whole raw image - needs to be segmented and saved\n",
    "#         b_d = plt.imread(brushlet_denoised_folder+files_list[1][i]) # whole brushlet denoised image - needs to be segmented and saved\n",
    "#         b_e = plt.imread(brushlet_enhanced_folder+files_list[2][i]) # whole brushlet enhanced image - needs to be segmented and saved\n",
    "        man_lab = plt.imread(manual_label_folder+files_list[3][i]) # main_label (coloured) - needs to be segmented and saved\n",
    "#         label = plt.imread(all_labels_folder+files_list[4][i]) # label (ids) - needs to be segmented and used to create weight\n",
    "#         label = ((label*7)/np.max(values)).astype(int)\n",
    "        \n",
    "        # Create my labels from manual labels\n",
    "#         save_label(man_lab, sim_labels_folder, new_file_list[i])\n",
    "#         sim_label = plt.imread(sim_labels_folder+files_list[5][i]) # label (ids) - needs to be segmented and used to create weight\n",
    "\n",
    "        correct_label = plt.imread(corrected_labels_folder+'label_'+new_file_list[i]+'_labels.png') # label (ids) - needs to be segmented and used to create weight\n",
    "        correct_label = ((correct_label*7)/np.max(values)).astype(int)\n",
    "#         print(np.unique(correct_label))\n",
    "        \n",
    "        # crop and save all files necessary\n",
    "        crop_and_save_raw(whole_raw, whole_raw_image_folder, new_file_list[i])\n",
    "#         crop_and_save_raw(b_d, brushlet_denoised_folder, new_file_list[i])\n",
    "#         crop_and_save_raw(b_e, brushlet_enhanced_folder, new_file_list[i])\n",
    "        crop_and_save_raw(man_lab, manual_label_folder, new_file_list[i])\n",
    "#         crop_and_save_label(label, all_labels_folder, new_file_list[i])\n",
    "#         crop_and_save_label(sim_label, sim_labels_folder, new_file_list[i])\n",
    "        crop_and_save_label(correct_label, corrected_labels_folder, new_file_list[i])\n",
    "\n",
    "#         image_array = [whole_raw, b_d, b_e, man_lab, label]    \n",
    "#         image_name = ['whole_raw_1', 'b_d_1', 'b_e_1', 'man_lab_1', 'label_1']\n",
    "\n",
    "#         fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15,5))\n",
    "#         fig.suptitle(new_file_list[i], size=14)\n",
    "#         for j, ax in enumerate(axes):\n",
    "#             ax.margins(0.05, 0.15)\n",
    "#             ax.imshow(image_array[j])\n",
    "#             ax.set_title(image_name[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(files_list[0][54])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # for i in range(len(files_list[0])):\n",
    "# for i in range(2):\n",
    "#     if i not in unwanted_files:\n",
    "#         man_lab = plt.imread(manual_label_folder+files_list[3][i])\n",
    "#     #     correct_label = plt.imread(corrected_labels_folder+files_list[6][i])\n",
    "#         correct_label = plt.imread(corrected_labels_folder+'label_'+new_file_list[i]+'_labels.png')\n",
    "#         correct_label = ((correct_label*7)/np.max(values)).astype(int)\n",
    "\n",
    "#         rgb_image = convert_to_rgb_image(correct_label)\n",
    "\n",
    "#         plt.figure(figsize=(15,5))\n",
    "#         plt.imshow(man_lab)\n",
    "#         plt.suptitle(new_file_list[i], size=15)\n",
    "\n",
    "#         print()\n",
    "#         print(new_file_list[i])\n",
    "#         print(np.unique(correct_label))\n",
    "\n",
    "#         plt.figure(figsize=(15,5))\n",
    "#         plt.imshow(correct_label)\n",
    "\n",
    "#         plt.figure(figsize=(15,5))\n",
    "#         plt.imshow(rgb_image)\n",
    "#         plt.show()\n",
    "#         h,w = correct_label.shape\n",
    "#         print(correct_label[400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create IMDB of dataset - HP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = list_all_files(whole_raw_image_folder+'Train/')\n",
    "H = 512\n",
    "W = 64\n",
    "N = len(files)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# atrium_ids = all_labels_folder+'Train/segmented_ids/'\n",
    "# atrium_weights = all_labels_folder+'Train/weights/'\n",
    "atrium_ids = corrected_labels_folder+'Train/segmented_ids/'\n",
    "atrium_weights = corrected_labels_folder+'Train/weights/'\n",
    "atrium_raw = whole_raw_image_folder +'Train/'\n",
    "\n",
    "atrium_id_files = {}\n",
    "atrium_weights_files = {}\n",
    "atrium_raw_files = {}\n",
    "for number, filename in enumerate(sorted(os.listdir(atrium_ids)), start=1):\n",
    "    atrium_id_files[number] = filename\n",
    "for number, filename in enumerate(sorted(os.listdir(atrium_weights)), start=1):\n",
    "    atrium_weights_files[number] = filename\n",
    "for number, filename in enumerate(sorted(os.listdir(atrium_raw)), start=1):\n",
    "    atrium_raw_files[number] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load h5py raw array\n",
    "def make_h5py_array_raw(src_direct, dictionary, count):\n",
    "    files = []\n",
    "    for i in range(1,len(dictionary)+1):\n",
    "        act_file = plt.imread(src_direct+dictionary[i])\n",
    "        act_file = np.array(act_file)\n",
    "        files.append(act_file)\n",
    "        count += 1\n",
    "    return files, count\n",
    "\n",
    "# Load h5py py array\n",
    "def make_h5py_array_npy(src_direct, dictionary, count):\n",
    "    files = []\n",
    "    for i in range(1,len(dictionary)+1):\n",
    "        act_file = np.load(src_direct+dictionary[i])\n",
    "        files.append(act_file)\n",
    "        \n",
    "        count += 1\n",
    "    return files, count\n",
    "count = 0\n",
    "id_files,num = make_h5py_array_npy(atrium_ids, atrium_id_files, count)\n",
    "print(len(id_files),num)\n",
    "weight_files,num = make_h5py_array_npy(atrium_weights, atrium_weights_files, count)\n",
    "print(len(weight_files),num)\n",
    "raw_files, num = make_h5py_array_raw(atrium_raw, atrium_raw_files, count)\n",
    "print(len(raw_files),num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Creating Data.h5 File\n",
    "data = np.zeros((N,1, H, W), dtype=np.float32)\n",
    "\n",
    "\n",
    "for i in range(N):\n",
    "    image = raw_files[i] # array of size (H,W)\n",
    "    for m in range(H):\n",
    "        for n in range(W):\n",
    "            data[i, 0, m, n] = image[m,n]\n",
    "data = data.astype('float32')\n",
    "print(type(data))\n",
    "\n",
    "# data = torch.from_numpy(data).float()\n",
    "data = torch.from_numpy(data)\n",
    "# data = torch.Tensor(data)\n",
    "print('Finalshape:',data.shape)\n",
    "hf = h5py.File('/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/Data.h5', 'w')\n",
    "hf.create_dataset('data', data=data) # creating raw data dataset - group name followed by dimensions in [H,W,Channel,DataIndex]\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating label.h5 File\n",
    "labels = np.zeros((N,2, H, W), dtype=np.float32)\n",
    "\n",
    "for i in range(N):\n",
    "    weights = weight_files[i] # array of size (H,W)\n",
    "    ids = id_files[i] # array of size (H,W) # class is your colour\n",
    "    \n",
    "    h,w = ids.shape\n",
    "    if h != 512 or w != 64:\n",
    "#         print(h,w)\n",
    "        amount = H - h\n",
    "        weight_full = np.full((amount, 64), 1.0)\n",
    "        id_full = np.full((amount, 64), 7)\n",
    "        weights = np.concatenate((weights, weight_full))\n",
    "        ids = np.concatenate((ids, id_full))   \n",
    "    new_id = np.copy(ids)\n",
    "    for m in range(H):\n",
    "        for n in range(W):\n",
    "            if ids[m,n] > 7:\n",
    "                # set all label values to 7 \n",
    "                new_id[m,n] = 7\n",
    "            labels[i, 0, m, n] = new_id[m,n]\n",
    "            labels[i, 1, m, n] = weights[m,n]\n",
    "            \n",
    "labels = labels.astype('float32')    \n",
    "print(type(labels))\n",
    "# labels = torch.from_numpy(labels).float()\n",
    "labels = torch.from_numpy(labels)\n",
    "# print(np.unique(labels[:,0,:,:]))\n",
    "print('Finalshape:',labels.shape)\n",
    "\n",
    "hf = h5py.File('/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/label.h5', 'w')\n",
    "hf.create_dataset('labels', data=labels) \n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating set.h5 File\n",
    "sets = np.ones((1,N))\n",
    "split = N * 0.8\n",
    "\n",
    "num_files = N\n",
    "validation_cutoff = int(split)\n",
    "\n",
    "# Making training set random\n",
    "train_indices = np.random.choice(num_files,validation_cutoff,replace = False)\n",
    "print(train_indices)\n",
    "test_indices = [x for x in range(num_files) if x not in train_indices]\n",
    "print(test_indices)\n",
    "for count,i in enumerate(sets[0]):\n",
    "    if count not in train_indices:\n",
    "        sets[0][count] = 3\n",
    "\n",
    "# sets[:,int(split):] = 3\n",
    "\n",
    "hf = h5py.File('/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/set.h5', 'w')\n",
    "hf.create_dataset('set', data=sets)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Creating Data.h5 File\n",
    "# data = np.zeros((N,1, H, W), dtype=np.float32)\n",
    "\n",
    "\n",
    "# for i in range(N):\n",
    "#     image = raw_files[i] # array of size (H,W)\n",
    "#     for m in range(H):\n",
    "#         for n in range(W):\n",
    "#             data[i, 0, m, n] = image[m,n]\n",
    "# data = data.astype('float32')\n",
    "# print(type(data))\n",
    "\n",
    "# # data = torch.from_numpy(data).float()\n",
    "# data = torch.from_numpy(data)\n",
    "# # # data = torch.Tensor(data)\n",
    "# print('Finalshape:',data.shape)\n",
    "# hf = h5py.File('/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/Data.h5', 'w')\n",
    "# hf.create_dataset('data', data=data) # creating raw data dataset - group name followed by dimensions in [H,W,Channel,DataIndex]\n",
    "# hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Creating label.h5 File\n",
    "# labels = np.zeros((N, 2, H, W), dtype=np.float32)\n",
    "\n",
    "# for i in range(N):\n",
    "#     weights = weight_files[i] # array of size (H,W)\n",
    "#     ids = id_files[i] # array of size (H,W) # class is your colour\n",
    "    \n",
    "#     h,w = ids.shape\n",
    "#     if h != 512 or w != 64:\n",
    "# #         print(h,w)\n",
    "#         amount = H - h\n",
    "#         weight_full = np.full((amount, 64), 1.0)\n",
    "#         id_full = np.full((amount, 64), 7)\n",
    "#         weights = np.concatenate((weights, weight_full))\n",
    "#         ids = np.concatenate((ids, id_full))   \n",
    "#     new_id = np.copy(ids)\n",
    "#     print(np.unique(new_id))\n",
    "#     for m in range(H):\n",
    "#         for n in range(W):\n",
    "#             if ids[m,n] > 7:\n",
    "#                 # set all label values to 7 \n",
    "#                 new_id[m,n] = 7\n",
    "#             labels[i, 0, m, n] = new_id[m,n]\n",
    "#             labels[i, 1, m, n] = weights[m,n]\n",
    "# #     print(np.unique(labels))\n",
    "# labels = labels.astype('float32')    \n",
    "# print(type(labels))\n",
    "# # labels = torch.from_numpy(labels).float()\n",
    "# labels = torch.from_numpy(labels)\n",
    "# print(np.unique(labels[:,0,:,:]))\n",
    "# print('Finalshape:',labels.shape)\n",
    "\n",
    "# hf = h5py.File('/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/label.h5', 'w')\n",
    "# hf.create_dataset('labels', data=labels) \n",
    "# hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Creating set.h5 File\n",
    "# sets = np.ones((1,N))\n",
    "# split = N * 0.8\n",
    "# sets[:,int(split):] = 3\n",
    "\n",
    "# hf = h5py.File('/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/set.h5', 'w')\n",
    "# hf.create_dataset('set', data=sets)\n",
    "# hf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
