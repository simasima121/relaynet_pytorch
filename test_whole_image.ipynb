{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pprint\n",
    "import cv2\n",
    "from scipy.misc import imsave\n",
    "from helper import *\n",
    "from create_labels import *\n",
    "from stats_helper import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.restoration as sr\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import scipy.io as scio\n",
    "from skimage import exposure\n",
    "from skimage.io import imsave, imread\n",
    "from scipy.misc import imresize\n",
    "from scipy.io import savemat\n",
    "from scipy import ndimage, misc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "from helper import *\n",
    "from stats_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Lambda \n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Reshape\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import regularizers, optimizers\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(filenames, root, ext):\n",
    "    images = []\n",
    "    for filename in filenames :\n",
    "        filepath = os.path.join(root,filename)\n",
    "        if ext == '.npy':\n",
    "            image = np.load(filepath)\n",
    "            h,w = image.shape\n",
    "            if h != 512 or w != 64:\n",
    "                amount = 512 - h\n",
    "                id_full = np.full((amount, 64), 0)\n",
    "                try:\n",
    "                    image = np.concatenate((image, id_full))\n",
    "                except Exception as e:\n",
    "                    print(image.shape)\n",
    "        elif ext == '.JPG' or ext == '.tif' or ext =='.png':\n",
    "            image = ndimage.imread(filepath)\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "def get_data(directory,ext):\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    \n",
    "    root_path = \"\"\n",
    "    filenames = [f for f in listdir(directory) if isfile(join(directory, f)) and f != '.DS_Store']\n",
    "    filenames = sorted(filenames)\n",
    "    return filenames, get_info(filenames, directory, ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder For Training Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the directories\n",
    "import os\n",
    "\n",
    "wanted_folder = 'alldata/'\n",
    "# wanted_folder = 'pruned/'\n",
    "# wanted_folder = 'Atrium/'\n",
    "# wanted_folder = 'Ventricle/'\n",
    "\n",
    "cwd = os.getcwd()\n",
    "check_directory = cwd\n",
    "if check_directory == '/home/sim/notebooks/relaynet_pytorch':\n",
    "    cwd = cwd + '/datasets/OCTData/'+wanted_folder\n",
    "elif check_directory == '/Users/sim/Desktop/Imperial/Project/PreTrained/relaynet_pytorch':\n",
    "    cwd = cwd + '/datasets-24-aug/OCTData/'+wanted_folder\n",
    "\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_raw_image_folder = cwd + 'whole_raw_image/'\n",
    "print(whole_raw_image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames, raw_images = get_data(whole_raw_image_folder, '.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filenames))\n",
    "print (len(raw_images))\n",
    "label = raw_images[0]\n",
    "label[440:,:] = 0\n",
    "plt.imshow(raw_images[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_label_folder = cwd + 'manual_label/'\n",
    "_, manual_labels = get_data(manual_label_folder,'.JPG')\n",
    "print(filenames[0])\n",
    "print(manual_labels[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,2,figsize=(20,20))\n",
    "plt.subplot(121), plt.imshow(raw_images[0], cmap = \"gray\")\n",
    "plt.title('Raw OCT Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122), plt.imshow(manual_labels[0])\n",
    "plt.title('Manually Labelled Image'), plt.xticks([]), plt.yticks([])\n",
    "# plt.subplot(133),plt.imshow(output)\n",
    "# plt.title('Automated Label'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_folder = cwd + 'png_labels_method/'\n",
    "_, ids = get_data(ids_folder,'.png')\n",
    "\n",
    "print (len(ids))\n",
    "print(ids[0].dtype)\n",
    "plt.imshow(ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w = 512, 600\n",
    "data_shape = h*w\n",
    "weight_decay = 0.0001\n",
    "# Defines the input tensor\n",
    "inputs = Input(shape=(h,w,1))\n",
    "\n",
    "L1 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(inputs)\n",
    "L2 = BatchNormalization()(L1)\n",
    "L2 = Activation('relu')(L2)\n",
    "#L3 = Lambda(maxpool_1,output_shape = shape)(L2)\n",
    "L3 = MaxPooling2D(pool_size=(2,2))(L2)\n",
    "L4 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L3)\n",
    "L5 = BatchNormalization()(L4)\n",
    "L5 = Activation('relu')(L5)\n",
    "#L6 = Lambda(maxpool_2,output_shape = shape)(L5)\n",
    "L6 = MaxPooling2D(pool_size=(2,2))(L5)\n",
    "L7 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L6)\n",
    "L8 = BatchNormalization()(L7)\n",
    "L8 = Activation('relu')(L8)\n",
    "#L9 = Lambda(maxpool_3,output_shape = shape)(L8)\n",
    "L9 = MaxPooling2D(pool_size=(2,2))(L8)\n",
    "L10 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L9)\n",
    "L11 = BatchNormalization()(L10)\n",
    "L11 = Activation('relu')(L11)\n",
    "L12 = UpSampling2D(size = (2,2))(L11)\n",
    "#L12 = Lambda(unpool_3,output_shape = unpool_shape)(L11)\n",
    "L13 = Concatenate(axis = 3)([L8,L12])\n",
    "L14 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L13)\n",
    "L15 = BatchNormalization()(L14)\n",
    "L15 = Activation('relu')(L15)\n",
    "L16 = UpSampling2D(size= (2,2))(L15)\n",
    "#L16 = Lambda(unpool_2,output_shape=unpool_shape)(L15)\n",
    "L17 = Concatenate(axis = 3)([L16,L5])\n",
    "L18 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L17)\n",
    "L19 = BatchNormalization()(L18)\n",
    "L19 = Activation('relu')(L19)\n",
    "#L20 = Lambda(unpool_1,output_shape=unpool_shape)(L19)\n",
    "L20 = UpSampling2D(size=(2,2),name = \"Layer19\")(L19)\n",
    "L21 = Concatenate(axis=3)([L20,L2])\n",
    "L22 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L21)\n",
    "L23 = BatchNormalization()(L22)\n",
    "L23 = Activation('relu')(L23)\n",
    "L24 = Conv2D(8,kernel_size=(1,1),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L23)\n",
    "L = Reshape((data_shape,8),input_shape = (h,w,8))(L24)\n",
    "L = Activation('softmax')(L)\n",
    "model = Model(inputs = inputs, outputs = L)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    '''\n",
    "    y_true = label\n",
    "    y_pred = prediction\n",
    "    '''\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_loss(y_true,y_pred):\n",
    "    cross_ent = K.categorical_crossentropy(y_true, y_pred)\n",
    "    loss_dice_coef = dice_coef_loss(y_true, y_pred)\n",
    "    return (1 * cross_ent)+(0.5*loss_dice_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [0.01]\n",
    "bs = 40\n",
    "epoch = 100\n",
    "for i in lrs:\n",
    "    optimiser = optimizers.Adam(lr = i)\n",
    "    model.compile(optimizer=optimiser,loss=customized_loss,metrics=['accuracy',dice_coef],sample_weight_mode='temporal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"/home/sim/notebooks/relaynet_pytorch/\"+saved_name+\".hdf5\")\n",
    "# saved_name = 'notnormalised_bs50_ep_500_01'\n",
    "saved_name = 'weightingval1_normalised_atriumventriclesubract_bs40_ep_200'\n",
    "model.load_weights(check_directory+\"/models/Normalised/\"+saved_name+\".hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(15*600)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def one_hot_encode(inp, num_classes):\n",
    "#     h,w = inp.shape\n",
    "#     encoding = np.zeros(( h, w, num_classes))\n",
    "#     for i in range(num_classes):\n",
    "#         encoding[:,:,i] = inp == i\n",
    "#     return encoding\n",
    "\n",
    "# def list_of_labels(label_img, num_classes):\n",
    "\n",
    "#     print(label_img.shape)\n",
    "#     train_labels = one_hot_encode(label_img, num_classes)\n",
    "#     return train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_stats = []\n",
    "# for i in range(len(filenames)):\n",
    "for i in range(2):\n",
    "    ind = i\n",
    "\n",
    "    # Raw Test Image \n",
    "    testing_image = raw_images[ind]\n",
    "    test_label = manual_labels[ind]\n",
    "    true_id = ids[ind]\n",
    "    \n",
    "    h,w = testing_image.shape\n",
    "\n",
    "    testing_image = testing_image.reshape((1,h,w,1))\n",
    "    prediction = model.predict(testing_image)\n",
    "    prediction = np.squeeze(prediction,axis = 0)\n",
    "\n",
    "    prediction = np.reshape(prediction,(h,w,8))\n",
    "\n",
    "    print(prediction.shape)\n",
    "    predicted_id = np.zeros((h,w))\n",
    "    # ground = np.zeros((h,w))\n",
    "\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            index = np.argmax(prediction[i][j]) # doing pixel wise prediction\n",
    "            predicted_id[i][j] = index\n",
    "#     idx = np.asarray(ids[0])\n",
    "#     print(idx.shape)\n",
    "\n",
    "    # Just used to plot the colours\n",
    "    print(np.unique(predicted_id))\n",
    "    \n",
    "    # Creating one hot encoding of true labels and predicted labels\n",
    "    true_labels = list_of_labels(true_id,8)\n",
    "    pred_labels = list_of_labels(predicted_id,8)\n",
    "    \n",
    "    stats = find_stats(true_labels, pred_labels)\n",
    "    overall_stats.append(stats)\n",
    "    \n",
    "    # Plotting Labels of the layers\n",
    "#     fig, axes = plt.subplots(nrows=1, ncols=8, figsize=(20,20))\n",
    "#     for i, ax in enumerate(axes):\n",
    "#         ax.imshow((true_labels[:,:,i]), alpha=0.2)\n",
    "#         ax.set_title(\"label \" + str(i))\n",
    "\n",
    "#     fig, axes = plt.subplots(nrows=1, ncols=8, figsize=(20,20))\n",
    "#     for i, ax in enumerate(axes):\n",
    "#         ax.imshow((pred_labels[:,:,i]), alpha=0.2)\n",
    "#         ax.set_title(\"label \" + str(i))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # color = label_img_to_rgb(predicted_id) \n",
    "    \n",
    "    \n",
    "#     f, axs = plt.subplots(1,3,figsize=(20,20))\n",
    "#     plt.subplot(131), plt.imshow(raw_images[ind], cmap = \"gray\")\n",
    "#     plt.title('Raw OCT Image'), plt.xticks([]), plt.yticks([])\n",
    "#     plt.subplot(132), plt.imshow(manual_labels[ind])\n",
    "#     plt.title('Manually Labelled Image'), plt.xticks([]), plt.yticks([])\n",
    "#     plt.subplot(133),plt.imshow(color)\n",
    "#     plt.title('Automated Label'), plt.xticks([]), plt.yticks([])\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=8, ncols=1, figsize=(20,20))\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.imshow(idx[:,:,i])\n",
    "#     ax.set_title(\"slice \" + str(i))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(overall_stats)):\n",
    "#     print('Image: {}, Stats: {}'.format(i,overall_stats[i]))\n",
    "#     TP,FP,TN,FN,Acc, Precision, Recall, Dice = overall_stats[i]\n",
    "#     print('Image:',i)\n",
    "#     print('TP: {}, FP: {}, TN: {}, FN: {}, Class Accuracy: {}, Precision: {}, Recall: {}, Dice: {}'.format(TP,FP,TN,FN,Acc, Precision, Recall, Dice))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,3,figsize=(20,20))\n",
    "plt.subplot(131), plt.imshow(raw_images[ind], cmap = \"gray\")\n",
    "plt.title('Raw OCT Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(132), plt.imshow(manual_labels[ind])\n",
    "plt.title('Manually Labelled Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(133),plt.imshow(color)\n",
    "plt.title('Automated Label'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(15,16):\n",
    "ind = 0\n",
    "\n",
    "# Raw Test Image \n",
    "testing_image = raw_images[ind]\n",
    "test_labels = manual_labels[ind]\n",
    "testing_image = testing_image[:,:]\n",
    "# segmented_images = segment_image(testing_image, 0, 600, 64)\n",
    "\n",
    "# testing_image = segmented_images[0]\n",
    "h,w = testing_image.shape\n",
    "\n",
    "testing_image = testing_image.reshape((1,h,w,1))\n",
    "prediction = model.predict(testing_image)\n",
    "prediction = np.squeeze(prediction,axis = 0)\n",
    "\n",
    "prediction = np.reshape(prediction,(h,w,8))\n",
    "\n",
    "print(prediction.shape)\n",
    "output = np.zeros((h,w))\n",
    "ground = np.zeros((h,w))\n",
    "for i in range(h):\n",
    "    for j in range(w):\n",
    "        index = np.argmax(prediction[i][j])\n",
    "        output[i][j] = index\n",
    "idx = np.asarray(ids[0])\n",
    "print(idx.shape)\n",
    "color = label_img_to_rgb(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
