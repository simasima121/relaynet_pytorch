{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pprint\n",
    "import cv2\n",
    "from scipy.misc import imsave\n",
    "from helper import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "# plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage.restoration as sr\n",
    "import numpy as np\n",
    "import glob\n",
    "# import h5py\n",
    "import os\n",
    "import scipy.io as scio\n",
    "from skimage import exposure\n",
    "from skimage.io import imsave, imread\n",
    "from scipy.misc import imresize\n",
    "from scipy.io import savemat\n",
    "from scipy import ndimage, misc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Lambda \n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Reshape\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import regularizers, optimizers\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_info(filenames, root, ext):\n",
    "    images = []\n",
    "    for filename in filenames :\n",
    "        filepath = os.path.join(root,filename)\n",
    "        if ext == '.npy':\n",
    "            image = np.load(filepath)\n",
    "            h,w = image.shape\n",
    "            \n",
    "            if h != 512 or w != 64:\n",
    "#                 print(h,w) \n",
    "                amount = 512 - h\n",
    "                id_full = np.full((amount, 64), 0)\n",
    "                image = np.concatenate((image, id_full))\n",
    "#                 print(image.shape)\n",
    "        elif ext == '.JPG' or ext == '.tif' or ext =='.png':\n",
    "            image = ndimage.imread(filepath, mode = \"L\")\n",
    "        images.append(image)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder For Training Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting the directories\n",
    "import os\n",
    "\n",
    "\n",
    "wanted_folder = 'alldata/'\n",
    "# wanted_folder = 'pruned/'\n",
    "# wanted_folder = 'Atrium/'\n",
    "# wanted_folder = 'Ventricle/'\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cwd = cwd + '/datasets/OCTData/'+wanted_folder\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whole_raw_image_folder = cwd + 'whole_raw_image/'\n",
    "print(whole_raw_image_folder)\n",
    "\n",
    "root_path = \"\"\n",
    "filenames = []\n",
    "for files in os.listdir(whole_raw_image_folder):\n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy', '.DS_Store']: \n",
    "        if files.endswith(ext):\n",
    "            filenames.append(files)\n",
    "filenames = sorted(filenames)\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_images = get_info(filenames, whole_raw_image_folder, '.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (len(raw_images))\n",
    "plt.imshow(raw_images[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manual_label_folder = cwd + 'manual_label/'\n",
    "print(whole_raw_image_folder)\n",
    "\n",
    "root_path = \"\"\n",
    "filenames = []\n",
    "for files in os.listdir(manual_label_folder):\n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy', '.DS_Store']: \n",
    "        if files.endswith(ext):\n",
    "            filenames.append(files)\n",
    "filenames = sorted(filenames)\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = get_info(filenames, manual_label_folder, '.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (len(labels))\n",
    "plt.imshow(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids_folder = cwd + 'png_labels_method/'\n",
    "print(ids_folder)\n",
    "\n",
    "root_path = \"\"\n",
    "filenames = []\n",
    "for files in os.listdir(ids_folder):\n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy', '.DS_Store']: \n",
    "        if files.endswith(ext):\n",
    "            filenames.append(files)\n",
    "filenames = sorted(filenames)\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = get_info(filenames, ids_folder, '.png')\n",
    "print (len(labels))\n",
    "plt.imshow(ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h,w = 512, 600\n",
    "data_shape = h*w\n",
    "weight_decay = 0.0001\n",
    "# Defines the input tensor\n",
    "inputs = Input(shape=(h,w,1))\n",
    "\n",
    "L1 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(inputs)\n",
    "L2 = BatchNormalization()(L1)\n",
    "L2 = Activation('relu')(L2)\n",
    "#L3 = Lambda(maxpool_1,output_shape = shape)(L2)\n",
    "L3 = MaxPooling2D(pool_size=(2,2))(L2)\n",
    "L4 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L3)\n",
    "L5 = BatchNormalization()(L4)\n",
    "L5 = Activation('relu')(L5)\n",
    "#L6 = Lambda(maxpool_2,output_shape = shape)(L5)\n",
    "L6 = MaxPooling2D(pool_size=(2,2))(L5)\n",
    "L7 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L6)\n",
    "L8 = BatchNormalization()(L7)\n",
    "L8 = Activation('relu')(L8)\n",
    "#L9 = Lambda(maxpool_3,output_shape = shape)(L8)\n",
    "L9 = MaxPooling2D(pool_size=(2,2))(L8)\n",
    "L10 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L9)\n",
    "L11 = BatchNormalization()(L10)\n",
    "L11 = Activation('relu')(L11)\n",
    "L12 = UpSampling2D(size = (2,2))(L11)\n",
    "#L12 = Lambda(unpool_3,output_shape = unpool_shape)(L11)\n",
    "L13 = Concatenate(axis = 3)([L8,L12])\n",
    "L14 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L13)\n",
    "L15 = BatchNormalization()(L14)\n",
    "L15 = Activation('relu')(L15)\n",
    "L16 = UpSampling2D(size= (2,2))(L15)\n",
    "#L16 = Lambda(unpool_2,output_shape=unpool_shape)(L15)\n",
    "L17 = Concatenate(axis = 3)([L16,L5])\n",
    "L18 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L17)\n",
    "L19 = BatchNormalization()(L18)\n",
    "L19 = Activation('relu')(L19)\n",
    "#L20 = Lambda(unpool_1,output_shape=unpool_shape)(L19)\n",
    "L20 = UpSampling2D(size=(2,2),name = \"Layer19\")(L19)\n",
    "L21 = Concatenate(axis=3)([L20,L2])\n",
    "L22 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L21)\n",
    "L23 = BatchNormalization()(L22)\n",
    "L23 = Activation('relu')(L23)\n",
    "L24 = Conv2D(8,kernel_size=(1,1),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L23)\n",
    "L = Reshape((data_shape,8),input_shape = (h,w,8))(L24)\n",
    "L = Activation('softmax')(L)\n",
    "model = Model(inputs = inputs, outputs = L)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    '''\n",
    "    y_true = label\n",
    "    y_pred = prediction\n",
    "    '''\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customized_loss(y_true,y_pred):\n",
    "    cross_ent = K.categorical_crossentropy(y_true, y_pred)\n",
    "    loss_dice_coef = dice_coef_loss(y_true, y_pred)\n",
    "    return (1 * cross_ent)+(0.5*loss_dice_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrs = [0.01]\n",
    "bs = 40\n",
    "epoch = 100\n",
    "for i in lrs:\n",
    "    optimiser = optimizers.Adam(lr = i)\n",
    "    model.compile(optimizer=optimiser,loss=customized_loss,metrics=['accuracy',dice_coef],sample_weight_mode='temporal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights(\"/home/sim/notebooks/relaynet_pytorch/\"+saved_name+\".hdf5\")\n",
    "# saved_name = 'notnormalised_bs50_ep_500_01'\n",
    "saved_name = 'notnormalised_bs40_ep_150'\n",
    "model.load_weights(\"/home/sim/notebooks/relaynet_pytorch/models/Normalised/\"+saved_name+\".hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEG_LABELS_LIST = [\n",
    "#     {\"id\": -1, \"name\": \"void\", \"rgb_values\": [0, 0, 0]},\n",
    "    {\"id\": 0, \"name\": \"void\", \"rgb_values\": [0, 0, 0]}, # black\n",
    "    {\"id\": 1, \"name\": \"Myocardium\", \"rgb_values\": [255,0,0]}, # red\n",
    "    {\"id\": 2, \"name\": \"Endocardium\", \"rgb_values\": [0, 0, 255]}, # blue\n",
    "    {\"id\": 3, \"name\": \"Fibrosis\", \"rgb_values\": [177,10,255]}, # purple\n",
    "    {\"id\": 4, \"name\": \"Fat\", \"rgb_values\": [0, 255, 0]}, # green\n",
    "    {\"id\": 5, \"name\": \"Dense Collagen\", \"rgb_values\": [255, 140, 0]}, # orange\n",
    "    {\"id\": 6, \"name\": \"Loose Collagen\", \"rgb_values\": [255, 255, 0]}, # yellow\n",
    "    {\"id\": 7, \"name\": \"Smooth Muscle\", \"rgb_values\": [255,0,255]}# magenta/pink\n",
    "]; \n",
    "\n",
    "def label_img_to_rgb(label_img):\n",
    "    label_img = np.squeeze(label_img)\n",
    "    labels = np.unique(label_img)\n",
    "    label_infos = [l for l in SEG_LABELS_LIST if l['id'] in labels]\n",
    "\n",
    "    label_img_rgb = np.array([label_img,\n",
    "                              label_img,\n",
    "                              label_img]).transpose(1,2,0)\n",
    "    for l in label_infos:\n",
    "        mask = label_img == l['id']\n",
    "        label_img_rgb[mask] = l['rgb_values']\n",
    "\n",
    "    return label_img_rgb.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(15*600)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range(15,16):\n",
    "ind = 0\n",
    "\n",
    "# Raw Test Image \n",
    "testing_image = raw_images[ind]\n",
    "test_labels=labels\n",
    "testing_image = testing_image[:,:64]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(testing_image, cmap=plt.cm.gray)\n",
    "\n",
    "# # Manual Test Image \n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.imshow(labels[ind])\n",
    "\n",
    "# testing_image = segmented_images[0]\n",
    "h,w = testing_image.shape\n",
    "\n",
    "testing_image = testing_image.reshape((1,h,w,1))\n",
    "prediction = model.predict(testing_image)\n",
    "prediction = np.squeeze(prediction,axis = 0)\n",
    "\n",
    "\n",
    "prediction = np.reshape(prediction,(h,w,8))\n",
    "\n",
    "print(prediction.shape)\n",
    "output = np.zeros((h,w))\n",
    "ground = np.zeros((h,w))\n",
    "for i in range(h):\n",
    "    for j in range(w):\n",
    "        index = np.argmax(prediction[i][j])\n",
    "        output[i][j] = index\n",
    "idx = np.asarray(ids[0])\n",
    "print(idx.shape)\n",
    "\n",
    "\n",
    "color = label_img_to_rgb(output)\n",
    "\n",
    "plt.imshow(color)\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=8, ncols=1, figsize=(20,20))\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.imshow(idx[:,:,i])\n",
    "#     ax.set_title(\"slice \" + str(i))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(15,16):\n",
    "ind = 0\n",
    "\n",
    "# Raw Test Image \n",
    "testing_image = raw_images[ind]\n",
    "test_labels=labels\n",
    "testing_image = testing_image[:,:64]\n",
    "# segmented_images = segment_image(testing_image, 0, 600, 64)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(testing_image, cmap=plt.cm.gray)\n",
    "\n",
    "# # Manual Test Image \n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.imshow(labels[ind])\n",
    "\n",
    "# testing_image = segmented_images[0]\n",
    "h,w = testing_image.shape\n",
    "\n",
    "testing_image = testing_image.reshape((1,h,w,1))\n",
    "prediction = model.predict(testing_image)\n",
    "prediction = np.squeeze(prediction,axis = 0)\n",
    "\n",
    "\n",
    "prediction = np.reshape(prediction,(h,w,8))\n",
    "\n",
    "print(prediction.shape)\n",
    "output = np.zeros((h,w))\n",
    "ground = np.zeros((h,w))\n",
    "for i in range(h):\n",
    "    for j in range(w):\n",
    "        index = np.argmax(prediction[i][j])\n",
    "        output[i][j] = index\n",
    "idx = np.asarray(ids[0])\n",
    "print(idx.shape)\n",
    "\n",
    "\n",
    "color = label_img_to_rgb(output)\n",
    "\n",
    "plt.imshow(color)\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=8, ncols=1, figsize=(20,20))\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.imshow(idx[:,:,i])\n",
    "#     ax.set_title(\"slice \" + str(i))\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF GPU",
   "language": "python",
   "name": "gputf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
