{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pprint\n",
    "import cv2\n",
    "from scipy.misc import imsave\n",
    "from helper import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Lambda \n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Reshape\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import regularizers, optimizers\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger,EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np    \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "# from scipy.misc import imsave\n",
    "from scipy import ndimage, misc\n",
    "from numpy import unravel_index\n",
    "from operator import sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_shape = 512*64\n",
    "weight_decay = 0.0001\n",
    "# Defines the input tensor\n",
    "inputs = Input(shape=(512,64,1))\n",
    "k,s = 5,5\n",
    "\n",
    "L1 = Conv2D(64,kernel_size=(k,s),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(inputs)\n",
    "L2 = BatchNormalization()(L1)\n",
    "L2 = Activation('relu')(L2)\n",
    "#L3 = Lambda(maxpool_1,output_shape = shape)(L2)\n",
    "L3 = MaxPooling2D(pool_size=(2,2))(L2)\n",
    "L4 = Conv2D(64,kernel_size=(k,s),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L3)\n",
    "L5 = BatchNormalization()(L4)\n",
    "L5 = Activation('relu')(L5)\n",
    "#L6 = Lambda(maxpool_2,output_shape = shape)(L5)\n",
    "L6 = MaxPooling2D(pool_size=(2,2))(L5)\n",
    "L7 = Conv2D(64,kernel_size=(k,s),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L6)\n",
    "L8 = BatchNormalization()(L7)\n",
    "L8 = Activation('relu')(L8)\n",
    "#L9 = Lambda(maxpool_3,output_shape = shape)(L8)\n",
    "L9 = MaxPooling2D(pool_size=(2,2))(L8)\n",
    "L10 = Conv2D(64,kernel_size=(k,s),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L9)\n",
    "L11 = BatchNormalization()(L10)\n",
    "L11 = Activation('relu')(L11)\n",
    "L12 = UpSampling2D(size = (2,2))(L11)\n",
    "#L12 = Lambda(unpool_3,output_shape = unpool_shape)(L11)\n",
    "L13 = Concatenate(axis = 3)([L8,L12])\n",
    "L14 = Conv2D(64,kernel_size=(k,s),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L13)\n",
    "L15 = BatchNormalization()(L14)\n",
    "L15 = Activation('relu')(L15)\n",
    "L16 = UpSampling2D(size= (2,2))(L15)\n",
    "#L16 = Lambda(unpool_2,output_shape=unpool_shape)(L15)\n",
    "L17 = Concatenate(axis = 3)([L16,L5])\n",
    "L18 = Conv2D(64,kernel_size=(k,s),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L17)\n",
    "L19 = BatchNormalization()(L18)\n",
    "L19 = Activation('relu')(L19)\n",
    "#L20 = Lambda(unpool_1,output_shape=unpool_shape)(L19)\n",
    "L20 = UpSampling2D(size=(2,2),name = \"Layer19\")(L19)\n",
    "L21 = Concatenate(axis=3)([L20,L2])\n",
    "L22 = Conv2D(64,kernel_size=(k,s),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L21)\n",
    "L23 = BatchNormalization()(L22)\n",
    "L23 = Activation('relu')(L23)\n",
    "L24 = Conv2D(8,kernel_size=(1,1),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L23)\n",
    "L = Reshape((data_shape,8),input_shape = (512,64,8))(L24)\n",
    "L = Activation('softmax')(L)\n",
    "model = Model(inputs = inputs, outputs = L)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    '''\n",
    "    y_true = label\n",
    "    y_pred = prediction\n",
    "    '''\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def customized_loss(y_true,y_pred):\n",
    "    cross_ent = K.categorical_crossentropy(y_true, y_pred)\n",
    "    loss_dice_coef = dice_coef_loss(y_true, y_pred)\n",
    "    return (1 * cross_ent)+(0.5*loss_dice_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_info(filenames, ext, root):\n",
    "    images = []\n",
    "    for filename in filenames :\n",
    "        filepath = os.path.join(root,filename)\n",
    "        if ext == '.npy':\n",
    "            image = np.load(filepath)\n",
    "            h,w = image.shape\n",
    "            if h != 512 or w != 64:\n",
    "                amount = 512 - h\n",
    "                id_full = np.full((amount, 64), 0)\n",
    "                try:\n",
    "                    image = np.concatenate((image, id_full))\n",
    "                except Exception as e:\n",
    "                    print(image.shape)\n",
    "        elif ext == '.JPG' or ext == '.tif' or ext =='.png':\n",
    "            image = ndimage.imread(filepath)\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "def get_data(directory,ext):\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    \n",
    "    root_path = \"\"\n",
    "    filenames = [f for f in listdir(directory) if isfile(join(directory, f)) and f != '.DS_Store']\n",
    "    filenames = sorted(filenames)\n",
    "    return filenames, get_info(filenames, ext, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting the directories\n",
    "import os\n",
    "\n",
    "# wanted_folder = 'alldata/'\n",
    "wanted_folder = 'pruned/'\n",
    "# wanted_folder = 'Atrium/'\n",
    "# wanted_folder = 'Ventricle/'\n",
    "\n",
    "cwd = os.getcwd()\n",
    "check_directory = cwd\n",
    "if check_directory == '/home/sim/notebooks/relaynet_pytorch':\n",
    "    cwd = cwd + '/datasets/OCTData/'+wanted_folder\n",
    "elif check_directory == '/Users/sim/Desktop/Imperial/Project/PreTrained/relaynet_pytorch':\n",
    "    cwd = cwd + '/datasets-24-aug/OCTData/'+wanted_folder\n",
    "\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filenames, raw_images = get_data(cwd+'whole_raw_image/Train','.png')\n",
    "filenames, raw_images = get_data(cwd+'normalised_raw_image/Train','.png')\n",
    "\n",
    "print(len(raw_images))\n",
    "print(filenames[128])\n",
    "print (raw_images[0].shape)\n",
    "plt.imshow(raw_images[6],cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Manual Labelled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting manual labelled Images\n",
    "_, manual_labels = get_data(cwd+'manual_label/Train','.png')\n",
    "print(filenames[128])\n",
    "print (manual_labels[2].shape)\n",
    "plt.imshow(manual_labels[0])\n",
    "print(np.asarray(manual_labels).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, labels_list = get_data(cwd+'/png_labels_method/Train/segmented_ids','.npy')\n",
    "print(len(labels_list), len(raw_images))\n",
    "print(filenames[128])\n",
    "print(labels_list[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing one hot encoding for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ids in labels_list:\n",
    "    h,w = ids.shape\n",
    "    if h != 512 or w != 64:\n",
    "        print(h,w)\n",
    "print(np.unique(labels_list))\n",
    "print(len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels = np.zeros((len(raw_images),512,64,8))\n",
    "print(train_labels.shape)\n",
    "val = 1\n",
    "for i in range(len(labels_list)) :\n",
    "    for lab in range(0,8):\n",
    "        train_labels[i,:,:, lab] = labels_list[i] == lab\n",
    "print(train_labels.shape)   \n",
    "print(train_labels[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, weights = get_data(cwd+'/png_labels_method/Train/weights','.npy')\n",
    "print(filenames[128])\n",
    "print(len(weights),weights[0].shape)\n",
    "print(weights[0][0][0])\n",
    "np.unique(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images=raw_images\n",
    "images=np.array(images)\n",
    "print(images.shape[0])\n",
    "images = images.reshape(images.shape[0],512,64,1)\n",
    "\n",
    "num_files = len(raw_images)\n",
    "validation_cutoff = int(len(raw_images)*0.8)\n",
    "\n",
    "train_indices = np.random.choice(num_files,validation_cutoff,replace = False)\n",
    "\n",
    "train_images_random = []\n",
    "train_labels_random = []\n",
    "\n",
    "for i in train_indices:\n",
    "    train_images_random.append(images[i])\n",
    "    train_labels_random.append(train_labels[i])\n",
    "\n",
    "test_indices = [x for x in range(num_files) if x not in train_indices]\n",
    "print(test_indices)\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for i in test_indices:\n",
    "    test_images.append(images[i])\n",
    "    test_labels.append(train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_images = np.array(train_images_random)\n",
    "train_labels = np.array(train_labels_random)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(train_images.shape, test_images.shape)\n",
    "print(train_labels.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32')\n",
    "train_labels = train_labels.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "test_labels = test_labels.astype('float32')\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (len(train_images))\n",
    "print (len(train_labels))\n",
    "print (np.array(train_labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,10))\n",
    "# plt.imshow(np.rot90(train_images[0,:,:,0]), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_matrix = []\n",
    "for i in train_indices:\n",
    "    weights_matrix.append(weights[i])\n",
    "print(len(weights_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_weights = np.array(weights_matrix)\n",
    "sample_weights = np.reshape(sample_weights,(validation_cutoff,data_shape))\n",
    "print(sample_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # (512, 600)\n",
    "# # 0 black\n",
    "# # 1 red\n",
    "# # 2 blue\n",
    "# # 3 purple\n",
    "# # 4 lime\n",
    "# # 5 orange\n",
    "# # 6 yellow\n",
    "# # 7 magenta\n",
    "# # magenta\n",
    "\n",
    "# print(manual_labels[train_indices[37]][127,:,:]) # The manual label that was done by Columbia\n",
    "# for i in range(8):\n",
    "#     print(i)\n",
    "#     print(train_labels[37,120,:,i]) # the trained_label I return/\n",
    "# ind = 256\n",
    "\n",
    "# plt.figure(figsize=(15,2))\n",
    "# plt.imshow(np.rot90(train_images[ind,:,:,0]), cmap=plt.cm.gray)\n",
    "# plt.suptitle(filenames[train_indices[ind]], size=15)\n",
    "\n",
    "# plt.figure(figsize=(15,2))\n",
    "# plt.imshow(np.rot90(manual_labels[train_indices[ind]]))\n",
    "\n",
    "# plt.figure(figsize=(15,2))\n",
    "# plt.imshow(np.rot90(np.reshape(sample_weights[ind], (512,64)) ))\n",
    "\n",
    "# # All the labels on top of each other\n",
    "# plt.figure(figsize=(15,2))\n",
    "# for i in range(7):\n",
    "#     plt.imshow(np.rot90(train_labels[ind,:,:,i]), alpha=0.2)\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=7, ncols=1, figsize=(15,20))\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.imshow(np.rot90(train_labels[ind,:,:,i]))\n",
    "#     ax.set_title(\"slice \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for j in range(3):\n",
    "#     plt.figure(figsize=(15,2))\n",
    "#     plt.imshow(np.rot90(train_images[j,:,:,0]), cmap=plt.cm.gray)\n",
    "#     plt.suptitle(filenames[train_indices[j]], size=15)\n",
    "    \n",
    "#     print(train_indices[j])\n",
    "#     plt.figure(figsize=(15,2))\n",
    "#     plt.imshow(np.rot90(manual_labels[train_indices[j]]))\n",
    "\n",
    "#     plt.figure(figsize=(15,2))\n",
    "#     plt.imshow(np.rot90(np.reshape(sample_weights[j], (512,64)) ))\n",
    "\n",
    "#     # All the labels on top of each other\n",
    "#     plt.figure(figsize=(15,2))\n",
    "#     for i in range(8):\n",
    "#         plt.imshow(np.rot90(train_labels[j,:,:,i]), alpha=0.2)\n",
    "\n",
    "#     fig, axes = plt.subplots(nrows=8, ncols=1, figsize=(15,20))\n",
    "#     for i, ax in enumerate(axes):\n",
    "#         ax.imshow(np.rot90(train_labels[j,:,:,i]))\n",
    "#         ax.set_title(\"slice \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=7, ncols=1, figsize=(20,20))\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.imshow(np.rot90(train_labels[0,:,:,i]))\n",
    "#     ax.set_title(\"slice \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first value is number of images\n",
    "print(len(train_images))\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = np.reshape(train_labels,(validation_cutoff,data_shape,8))\n",
    "test_labels = np.reshape(test_labels,(num_files-validation_cutoff,data_shape,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = np.zeros(8)\n",
    "count = np.sum(train_labels==1,axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# His are floats\n",
    "new_count = np.zeros(8)\n",
    "for i in range(8):\n",
    "    new_count[i] = float(count[i])\n",
    "#     print(new_count[i])\n",
    "count = new_count\n",
    "for i in range(8):\n",
    "    print(count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "median = np.median(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(k,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrs = [0.01]\n",
    "bs = 40\n",
    "epoch = 150\n",
    "\n",
    "# Normalised Test\n",
    "# named = \"models/Normalised/raw_bs_{}_ep_{}\".format(bs,epoch)\n",
    "# named = \"models/Normalised/normalised_bs_{}_ep_{}\".format(bs,epoch)\n",
    "\n",
    "# Kernel Test\n",
    "# named = \"models/Kernel/ks{}{}_bs_{}_ep_{}\".format(k,s,bs,epoch).replace('.','_')\n",
    "\n",
    "# Weights Test\n",
    "# named = \"models/Weights/p4r8g11mag6bs_{}_ep_{}\".format(bs,epoch)\n",
    "\n",
    "# Epochs Test\n",
    "epoch=120\n",
    "named = \"models/Epochs/normalised_bs_{}_ep_{}\".format(bs,epoch)\n",
    "\n",
    "print(named)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in lrs:\n",
    "    # LR Test\n",
    "#     named = \"models/LR/lr{}_bs_{}_ep_{}\".format(i,bs,epoch).replace('.','')\n",
    "#     print(named)\n",
    "    \n",
    "    optimiser = optimizers.Adam(lr = i)\n",
    "    model.compile(optimizer=optimiser,loss=customized_loss,metrics=['accuracy',dice_coef],sample_weight_mode='temporal')\n",
    "    \n",
    "    #Defining Callback functions which will be called by model during runtime when specified condition satisfies\n",
    "    saved_name = named\n",
    "    lr_reducer = ReduceLROnPlateau(factor=0.5, cooldown=0, patience=6, min_lr=0.5e-6)\n",
    "    csv_logger = CSVLogger(saved_name+'.csv')\n",
    "    model_chekpoint = ModelCheckpoint(saved_name+\".hdf5\",monitor = 'val_loss',verbose = 1,save_best_only=True)\n",
    "    print('================'+str(i)+'===================')\n",
    "    model.fit(train_images,train_labels,batch_size=bs,epochs=epoch,validation_data=(test_images,test_labels),sample_weight=sample_weights,callbacks=[lr_reducer,csv_logger,model_chekpoint])\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights(\"/home/sim/notebooks/relaynet_pytorch/\"+saved_name+\".hdf5\")\n",
    "# # saved_name = 'notnormalised_bs50_ep_500_01'\n",
    "# # model.load_weights(\"/home/sim/notebooks/relaynet_pytorch/models/Trained_Networks/\"+saved_name+\".hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SEG_LABELS_LIST = [\n",
    "# #     {\"id\": -1, \"name\": \"void\", \"rgb_values\": [0, 0, 0]},\n",
    "#     {\"id\": 0, \"name\": \"void\", \"rgb_values\": [0, 0, 0]}, # black\n",
    "#     {\"id\": 1, \"name\": \"Myocardium\", \"rgb_values\": [255,0,0]}, # red\n",
    "#     {\"id\": 2, \"name\": \"Endocardium\", \"rgb_values\": [0, 0, 255]}, # blue\n",
    "#     {\"id\": 3, \"name\": \"Fibrosis\", \"rgb_values\": [177,10,255]}, # purple\n",
    "#     {\"id\": 4, \"name\": \"Fat\", \"rgb_values\": [0, 255, 0]}, # green\n",
    "#     {\"id\": 5, \"name\": \"Dense Collagen\", \"rgb_values\": [255, 140, 0]}, # orange\n",
    "#     {\"id\": 6, \"name\": \"Loose Collagen\", \"rgb_values\": [255, 255, 0]}, # yellow\n",
    "#     {\"id\": 7, \"name\": \"Smooth Muscle\", \"rgb_values\": [255,0,255]}# magenta/pink\n",
    "# ]; \n",
    "\n",
    "# def label_img_to_rgb(label_img):\n",
    "#     label_img = np.squeeze(label_img)\n",
    "#     labels = np.unique(label_img)\n",
    "#     label_infos = [l for l in SEG_LABELS_LIST if l['id'] in labels]\n",
    "\n",
    "#     label_img_rgb = np.array([label_img,\n",
    "#                               label_img,\n",
    "#                               label_img]).transpose(1,2,0)\n",
    "#     for l in label_infos:\n",
    "#         mask = label_img == l['id']\n",
    "#         label_img_rgb[mask] = l['rgb_values']\n",
    "\n",
    "#     return label_img_rgb.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(10,11):\n",
    "#     ind = i\n",
    "    \n",
    "#     # Raw Test Image \n",
    "#     testing_image = train_images[ind]\n",
    "#     testing_image = np.squeeze(testing_image,axis = 2)\n",
    "#     plt.figure(figsize=(20,10))\n",
    "#     plt.imshow(np.rot90(testing_image), cmap=plt.cm.gray)\n",
    "    \n",
    "#     # Manual Test Image \n",
    "#     plt.figure(figsize=(15,2))\n",
    "#     plt.imshow(np.rot90(manual_labels[train_indices[ind]]))\n",
    "\n",
    "#     plt.figure(figsize=(20,10))\n",
    "#     new_train_labels = np.copy(train_labels)\n",
    "#     new_train_labels = new_train_labels.reshape((validation_cutoff,512,64,8))\n",
    "#     for i in range(7):\n",
    "#         plt.imshow(np.rot90(new_train_labels[ind,:,:,i]), alpha=0.5)\n",
    "    \n",
    "#     fig, axes = plt.subplots(nrows=1, ncols=7, figsize=(50,50))\n",
    "#     for i, ax in enumerate(axes):\n",
    "#         ax.imshow(np.rot90(new_train_labels[ind,:,:,i]))\n",
    "#         ax.set_title(\"slice \" + str(i))\n",
    "#     plt.show()\n",
    "\n",
    "#     testing_image = testing_image.reshape((1,512,64,1))\n",
    "#     prediction = model.predict(testing_image)\n",
    "#     prediction = np.squeeze(prediction,axis = 0)\n",
    "    \n",
    "#     np.argmax(prediction[6999])\n",
    "\n",
    "#     prediction = np.reshape(prediction,(512,64,8))\n",
    "#     output = np.zeros((512,64))\n",
    "#     ground = np.zeros((512,64))\n",
    "#     for i in range(512):\n",
    "#         for j in range(64):\n",
    "#             index = np.argmax(prediction[i][j])\n",
    "#             output[i][j] = index\n",
    "#     test_labels[0].shape\n",
    "\n",
    "#     # test_labels[20][6999]\n",
    "\n",
    "#     test_ground_truth = np.reshape(train_labels[ind],(512,64,8))\n",
    "#     for i in range(512):\n",
    "#         for j in range(64):\n",
    "#             index = np.argmax(test_ground_truth[i][j])\n",
    "#             ground[i][j] = index\n",
    "#     for i in range(512):\n",
    "#         for j in range(64):\n",
    "#             index = np.argmax(prediction[i][j])\n",
    "#             output[i][j] = index\n",
    "#     print (output.shape)\n",
    "    \n",
    "#     print(np.unique(output))\n",
    "\n",
    "#     color = np.zeros((512,64,3))\n",
    "#     c0 = 0\n",
    "#     c1 = 0\n",
    "#     c2 = 0\n",
    "#     c3 = 0\n",
    "#     c4 = 0\n",
    "#     c5 = 0\n",
    "#     c6 = 0\n",
    "#     c7 = 0\n",
    "#     for j in range(512):\n",
    "#         for k in range(64):\n",
    "#             if(output[j][k]==0):\n",
    "#                 c0 = c0 + 1\n",
    "#                 color[j][k] = [0,0,0]\n",
    "#             if(output[j][k]==1):\n",
    "#                 c1 = c1 + 1\n",
    "#                 color[j][k] = [255,0,0]\n",
    "#             if(output[j][k]==2):\n",
    "#                 c2 = c2 + 1\n",
    "#                 color[j][k] = [0, 0, 255]\n",
    "#             if(output[j][k]==3):\n",
    "#                 c3 = c3 + 1\n",
    "#                 color[j][k] = [177,10,255] \n",
    "#             if(output[j][k]==4):\n",
    "#                 c4 = c4 + 1\n",
    "#                 color[j][k] = [0,255,0]\n",
    "#             if(output[j][k]==5):\n",
    "#                 c5 = c5 + 1\n",
    "#                 color[j][k] = [255, 140, 0]\n",
    "#             if(output[j][k]==6):\n",
    "#                 c6 = c6 + 1\n",
    "#                 color[j][k] = [255, 255, 0]\n",
    "#             if(output[j][k]==7):\n",
    "#                 c7 = c7 + 1\n",
    "#                 color[j][k] = [255,0,255]\n",
    "\n",
    "#     print('index 0:', c0)\n",
    "#     print('index 1:', c1)\n",
    "#     print('index 2:', c2)\n",
    "#     print('index 3:', c3)\n",
    "#     print('index 4:', c4)\n",
    "#     print('index 5:', c5)\n",
    "#     print('index 6:', c6)\n",
    "#     print('index 7:', c7)\n",
    "\n",
    "#     %matplotlib inline\n",
    "#     plt.figure(figsize=(20,10))\n",
    "#     plt.imshow(np.rot90(color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(10,11):\n",
    "#     ind = i\n",
    "\n",
    "#     # Raw Test Image \n",
    "#     testing_image = train_images[ind]\n",
    "#     testing_image = np.squeeze(testing_image,axis = 2)\n",
    "#     plt.figure(figsize=(20,10))\n",
    "#     plt.imshow(np.rot90(testing_image), cmap=plt.cm.gray)\n",
    "\n",
    "#     # Manual Test Image \n",
    "#     plt.figure(figsize=(15,2))\n",
    "#     plt.imshow(np.rot90(manual_labels[train_indices[ind]]))\n",
    "\n",
    "#     # Layers all overlayed\n",
    "#     # plt.figure(figsize=(20,10))\n",
    "#     # new_train_labels = np.copy(train_labels)\n",
    "#     # new_train_labels = new_train_labels.reshape((validation_cutoff,512,64,8))\n",
    "#     # for i in range(7):\n",
    "#     #     plt.imshow(np.rot90(new_train_labels[ind,:,:,i]), alpha=0.5)\n",
    "\n",
    "#     # fig, axes = plt.subplots(nrows=7, ncols=1, figsize=(20,20))\n",
    "#     # for i, ax in enumerate(axes):\n",
    "#     #     ax.imshow(np.rot90(new_train_labels[ind,:,:,i]))\n",
    "#     #     ax.set_title(\"slice \" + str(i))\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "#     testing_image = testing_image.reshape((1,512,64,1))\n",
    "#     print(testing_image.shape)\n",
    "#     prediction = model.predict(testing_image)\n",
    "#     prediction = np.squeeze(prediction,axis = 0)\n",
    "\n",
    "#     # np.argmax(prediction[6999])\n",
    "\n",
    "#     prediction = np.reshape(prediction,(512,64,8))\n",
    "#     output = np.zeros((512,64))\n",
    "#     ground = np.zeros((512,64))\n",
    "#     for i in range(512):\n",
    "#         for j in range(64):\n",
    "#             index = np.argmax(prediction[i][j])\n",
    "#             output[i][j] = index\n",
    "#     test_labels[0].shape\n",
    "\n",
    "#     # test_labels[20][6999]\n",
    "\n",
    "#     test_ground_truth = np.reshape(train_labels[ind],(512,64,8))\n",
    "#     for i in range(512):\n",
    "#         for j in range(64):\n",
    "#             index = np.argmax(test_ground_truth[i][j])\n",
    "#             ground[i][j] = index\n",
    "#     for i in range(512):\n",
    "#         for j in range(64):\n",
    "#             index = np.argmax(prediction[i][j])\n",
    "#             output[i][j] = index\n",
    "#     print (output.shape)\n",
    "\n",
    "#     print(np.unique(train_labels[ind]))\n",
    "#     print(np.unique(output))\n",
    "\n",
    "#     color = label_img_to_rgb(output)\n",
    "\n",
    "#     %matplotlib inline\n",
    "#     plt.figure(figsize=(20,10))\n",
    "#     plt.imshow(np.rot90(color))\n",
    "\n",
    "#     plt.figure(figsize=(20,10))\n",
    "#     for i in range(7):\n",
    "#         plt.imshow(np.rot90(output), alpha=0.5)\n",
    "\n",
    "#     new_output = np.zeros((512,64,8))\n",
    "#     for j in range(512) :\n",
    "#         for k in range(64):\n",
    "#             if(output[j][k] == 0):\n",
    "#                 new_output[j][k][0] = 1\n",
    "#             if(output[j][k] == 1):\n",
    "#                 new_output[j][k][1] = 1\n",
    "#             if(output[j][k] == 2):\n",
    "#                 new_output[j][k][2] = 1\n",
    "#             if(output[j][k] == 3):\n",
    "#                 new_output[j][k][3] = 1\n",
    "#             if(output[j][k] == 4):\n",
    "#                 new_output[j][k][4] = 1\n",
    "#             if(output[j][k] == 5):\n",
    "#                 new_output[j][k][5] = 1\n",
    "#             if(output[j][k] == 6):\n",
    "#                 new_output[j][k][6] = 1\n",
    "#             if(output[j][k] == 7):\n",
    "#                 new_output[j][k][7] = 1\n",
    "#     fig, axes = plt.subplots(nrows=7, ncols=1, figsize=(20,20))\n",
    "#     for i, ax in enumerate(axes):\n",
    "#         ax.imshow(np.rot90(new_output[:,:,i]))\n",
    "#         ax.set_title(\"slice \" + str(i))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For notnormalised, 10 and 11 are good example pics of a fuck up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ind = 11\n",
    "\n",
    "# # Raw Test Image \n",
    "# testing_image = train_images[ind]\n",
    "# testing_image = np.squeeze(testing_image,axis = 2)\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.imshow(np.rot90(testing_image), cmap=plt.cm.gray)\n",
    "\n",
    "# # Manual Test Image \n",
    "# plt.figure(figsize=(15,2))\n",
    "# plt.imshow(np.rot90(manual_labels[train_indices[ind]]))\n",
    "\n",
    "# # Layers all overlayed\n",
    "# # plt.figure(figsize=(20,10))\n",
    "# # new_train_labels = np.copy(train_labels)\n",
    "# # new_train_labels = new_train_labels.reshape((validation_cutoff,512,64,8))\n",
    "# # for i in range(7):\n",
    "# #     plt.imshow(np.rot90(new_train_labels[ind,:,:,i]), alpha=0.5)\n",
    "\n",
    "# # fig, axes = plt.subplots(nrows=7, ncols=1, figsize=(20,20))\n",
    "# # for i, ax in enumerate(axes):\n",
    "# #     ax.imshow(np.rot90(new_train_labels[ind,:,:,i]))\n",
    "# #     ax.set_title(\"slice \" + str(i))\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# testing_image = testing_image.reshape((1,512,64,1))\n",
    "# print(testing_image.shape)\n",
    "# prediction = model.predict(testing_image)\n",
    "# prediction = np.squeeze(prediction,axis = 0)\n",
    "\n",
    "# # np.argmax(prediction[6999])\n",
    "\n",
    "# prediction = np.reshape(prediction,(512,64,8))\n",
    "# output = np.zeros((512,64))\n",
    "# ground = np.zeros((512,64))\n",
    "# for i in range(512):\n",
    "#     for j in range(64):\n",
    "#         index = np.argmax(prediction[i][j])\n",
    "#         output[i][j] = index\n",
    "# test_labels[0].shape\n",
    "\n",
    "# # test_labels[20][6999]\n",
    "\n",
    "# test_ground_truth = np.reshape(train_labels[ind],(512,64,8))\n",
    "# for i in range(512):\n",
    "#     for j in range(64):\n",
    "#         index = np.argmax(test_ground_truth[i][j])\n",
    "#         ground[i][j] = index\n",
    "# for i in range(512):\n",
    "#     for j in range(64):\n",
    "#         index = np.argmax(prediction[i][j])\n",
    "#         output[i][j] = index\n",
    "# print (output.shape)\n",
    "\n",
    "# print(np.unique(train_labels[ind]))\n",
    "# print(np.unique(output))\n",
    "\n",
    "# color = label_img_to_rgb(output)\n",
    "\n",
    "# %matplotlib inline\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.imshow(np.rot90(color))\n",
    "\n",
    "# plt.figure(figsize=(20,10))\n",
    "# for i in range(7):\n",
    "#     plt.imshow(np.rot90(output), alpha=0.5)\n",
    "    \n",
    "# new_output = np.zeros((512,64,8))\n",
    "# for j in range(512) :\n",
    "#     for k in range(64):\n",
    "#         if(output[j][k] == 0):\n",
    "#             new_output[j][k][0] = 1\n",
    "#         if(output[j][k] == 1):\n",
    "#             new_output[j][k][1] = 1\n",
    "#         if(output[j][k] == 2):\n",
    "#             new_output[j][k][2] = 1\n",
    "#         if(output[j][k] == 3):\n",
    "#             new_output[j][k][3] = 1\n",
    "#         if(output[j][k] == 4):\n",
    "#             new_output[j][k][4] = 1\n",
    "#         if(output[j][k] == 5):\n",
    "#             new_output[j][k][5] = 1\n",
    "#         if(output[j][k] == 6):\n",
    "#             new_output[j][k][6] = 1\n",
    "#         if(output[j][k] == 7):\n",
    "#             new_output[j][k][7] = 1\n",
    "# fig, axes = plt.subplots(nrows=7, ncols=1, figsize=(20,20))\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.imshow(np.rot90(new_output[:,:,i]))\n",
    "#     ax.set_title(\"slice \" + str(i))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init_g = tf.global_variables_initializer()\n",
    "# init_l = tf.local_variables_initializer()\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init_g)\n",
    "#     sess.run(init_l)\n",
    "# #     var = [v for v in tf.trainable_variables()]\n",
    "\n",
    "# #     vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "#     tvars = tf.trainable_variables()\n",
    "#     tvars_vals = sess.run(tvars)\n",
    "\n",
    "#     for var, val in zip(tvars, tvars_vals):\n",
    "#         print(var.name, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF GPU",
   "language": "python",
   "name": "gputf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
