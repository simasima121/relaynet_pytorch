{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pprint\n",
    "import cv2\n",
    "from scipy.misc import imsave\n",
    "from helper import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Lambda \n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Reshape\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import regularizers, optimizers\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth=True\n",
    "\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger,EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np    \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "# from scipy.misc import imsave\n",
    "from scipy import ndimage, misc\n",
    "from numpy import unravel_index\n",
    "from operator import sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_shape = 512*64\n",
    "weight_decay = 0.0001\n",
    "# Defines the input tensor\n",
    "inputs = Input(shape=(512,64,1))\n",
    "k,s = 5,5\n",
    "\n",
    "L1 = Conv2D(64,kernel_size=(k,s),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(inputs)\n",
    "L2 = BatchNormalization()(L1)\n",
    "L2 = Activation('relu')(L2)\n",
    "#L3 = Lambda(maxpool_1,output_shape = shape)(L2)\n",
    "L3 = MaxPooling2D(pool_size=(2,2))(L2)\n",
    "L4 = Conv2D(64,kernel_size=(k,s),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L3)\n",
    "L5 = BatchNormalization()(L4)\n",
    "L5 = Activation('relu')(L5)\n",
    "#L6 = Lambda(maxpool_2,output_shape = shape)(L5)\n",
    "L6 = MaxPooling2D(pool_size=(2,2))(L5)\n",
    "L7 = Conv2D(64,kernel_size=(k,s),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L6)\n",
    "L8 = BatchNormalization()(L7)\n",
    "L8 = Activation('relu')(L8)\n",
    "#L9 = Lambda(maxpool_3,output_shape = shape)(L8)\n",
    "L9 = MaxPooling2D(pool_size=(2,2))(L8)\n",
    "L10 = Conv2D(64,kernel_size=(k,s),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L9)\n",
    "L11 = BatchNormalization()(L10)\n",
    "L11 = Activation('relu')(L11)\n",
    "L12 = UpSampling2D(size = (2,2))(L11)\n",
    "#L12 = Lambda(unpool_3,output_shape = unpool_shape)(L11)\n",
    "L13 = Concatenate(axis = 3)([L8,L12])\n",
    "L14 = Conv2D(64,kernel_size=(k,s),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L13)\n",
    "L15 = BatchNormalization()(L14)\n",
    "L15 = Activation('relu')(L15)\n",
    "L16 = UpSampling2D(size= (2,2))(L15)\n",
    "#L16 = Lambda(unpool_2,output_shape=unpool_shape)(L15)\n",
    "L17 = Concatenate(axis = 3)([L16,L5])\n",
    "L18 = Conv2D(64,kernel_size=(k,s),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L17)\n",
    "L19 = BatchNormalization()(L18)\n",
    "L19 = Activation('relu')(L19)\n",
    "#L20 = Lambda(unpool_1,output_shape=unpool_shape)(L19)\n",
    "L20 = UpSampling2D(size=(2,2),name = \"Layer19\")(L19)\n",
    "L21 = Concatenate(axis=3)([L20,L2])\n",
    "L22 = Conv2D(64,kernel_size=(k,s),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L21)\n",
    "L23 = BatchNormalization()(L22)\n",
    "L23 = Activation('relu')(L23)\n",
    "L24 = Conv2D(8,kernel_size=(1,1),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L23)\n",
    "L = Reshape((data_shape,8),input_shape = (512,64,8))(L24)\n",
    "L = Activation('softmax')(L)\n",
    "model = Model(inputs = inputs, outputs = L)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    '''\n",
    "    y_true = label\n",
    "    y_pred = prediction\n",
    "    '''\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def customized_loss(y_true,y_pred):\n",
    "    cross_ent = K.categorical_crossentropy(y_true, y_pred)\n",
    "    loss_dice_coef = dice_coef_loss(y_true, y_pred)\n",
    "    return (1 * cross_ent)+(0.5*loss_dice_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_info(filenames, ext, root):\n",
    "    images = []\n",
    "    for filename in filenames :\n",
    "        filepath = os.path.join(root,filename)\n",
    "        if ext == '.npy':\n",
    "            image = np.load(filepath)\n",
    "            h,w = image.shape\n",
    "            if h != 512 or w != 64:\n",
    "                amount = 512 - h\n",
    "                id_full = np.full((amount, 64), 0)\n",
    "                try:\n",
    "                    image = np.concatenate((image, id_full))\n",
    "                except Exception as e:\n",
    "                    print(image.shape)\n",
    "        elif ext == '.JPG' or ext == '.tif' or ext =='.png':\n",
    "            image = ndimage.imread(filepath)\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "def get_data(directory,ext):\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    \n",
    "    root_path = \"\"\n",
    "    filenames = [f for f in listdir(directory) if isfile(join(directory, f)) and f != '.DS_Store']\n",
    "    filenames = sorted(filenames)\n",
    "    return filenames, get_info(filenames, ext, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting the directories\n",
    "import os\n",
    "\n",
    "# wanted_folder = 'alldata/'\n",
    "wanted_folder = 'pruned/'\n",
    "# wanted_folder = 'Atrium/'\n",
    "# wanted_folder = 'Ventricle/'\n",
    "\n",
    "cwd = os.getcwd()\n",
    "check_directory = cwd\n",
    "if check_directory == '/home/sim/notebooks/relaynet_pytorch':\n",
    "    cwd = cwd + '/datasets/OCTData/'+wanted_folder\n",
    "elif check_directory == '/Users/sim/Desktop/Imperial/Project/PreTrained/relaynet_pytorch':\n",
    "    cwd = cwd + '/datasets-24-aug/OCTData/'+wanted_folder\n",
    "\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filenames, raw_images = get_data(cwd+'whole_raw_image/Train','.png')\n",
    "\n",
    "# Normalised\n",
    "filenames, raw_images = get_data(cwd+'normalised_raw_image/Train','.png')\n",
    "\n",
    "# Denoised\n",
    "# filenames, raw_images = get_data(cwd+'normalised_brushlet_enhanced/Train','.png')\n",
    "# filenames, raw_images = get_data(cwd+'normalised_brushlet_denoised/Train','.png')\n",
    "# filenames, raw_images = get_data(cwd+'normalised_bm3d/Train','.png')\n",
    "# filenames, raw_images = get_data(cwd+'normalised_nl_means/Train','.png')\n",
    "# filenames, raw_images = get_data(cwd+'normalised_bilateral_filter/Train','.png')\n",
    "\n",
    "print(len(raw_images))\n",
    "print(filenames[128])\n",
    "print (raw_images[0].shape)\n",
    "plt.imshow(raw_images[2],cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Manual Labelled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting manual labelled Images\n",
    "_, manual_labels = get_data(cwd+'manual_label/Train','.png')\n",
    "print(filenames[128])\n",
    "print (manual_labels[2].shape)\n",
    "plt.imshow(manual_labels[0])\n",
    "print(np.asarray(manual_labels).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, labels_list = get_data(cwd+'/png_labels_method/Train/segmented_ids','.npy')\n",
    "print(len(labels_list), len(raw_images))\n",
    "print(filenames[128])\n",
    "print(labels_list[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing one hot encoding for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ids in labels_list:\n",
    "    h,w = ids.shape\n",
    "    if h != 512 or w != 64:\n",
    "        print(h,w)\n",
    "print(np.unique(labels_list))\n",
    "print(len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels = np.zeros((len(raw_images),512,64,8))\n",
    "print(train_labels.shape)\n",
    "val = 1\n",
    "for i in range(len(labels_list)) :\n",
    "    for lab in range(0,8):\n",
    "        train_labels[i,:,:, lab] = labels_list[i] == lab\n",
    "print(train_labels.shape)   \n",
    "print(train_labels[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, weights = get_data(cwd+'/png_labels_method/Train/weights','.npy')\n",
    "print(filenames[128])\n",
    "print(len(weights),weights[0].shape)\n",
    "print(weights[0][0][0])\n",
    "np.unique(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "images=raw_images\n",
    "images=np.array(images)\n",
    "print(images.shape[0])\n",
    "images = images.reshape(images.shape[0],512,64,1)\n",
    "\n",
    "num_files = len(raw_images)\n",
    "validation_cutoff = int(len(raw_images)*0.8)\n",
    "\n",
    "train_indices = np.random.choice(num_files,validation_cutoff,replace = False)\n",
    "\n",
    "train_images_random = []\n",
    "train_labels_random = []\n",
    "\n",
    "for i in train_indices:\n",
    "    train_images_random.append(images[i])\n",
    "    train_labels_random.append(train_labels[i])\n",
    "\n",
    "\n",
    "test_indices = [x for x in range(num_files) if x not in train_indices]\n",
    "print(test_indices)\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for i in test_indices:\n",
    "    test_images.append(images[i])\n",
    "    test_labels.append(train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_images = np.array(train_images_random)\n",
    "train_labels = np.array(train_labels_random)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(train_images.shape, test_images.shape)\n",
    "print(train_labels.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32')\n",
    "train_labels = train_labels.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "test_labels = test_labels.astype('float32')\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (len(train_images))\n",
    "print (len(train_labels))\n",
    "print (np.array(train_labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_matrix = []\n",
    "for i in train_indices:\n",
    "    weights_matrix.append(weights[i])\n",
    "print(len(weights_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_weights = np.array(weights_matrix)\n",
    "sample_weights = np.reshape(sample_weights,(validation_cutoff,data_shape))\n",
    "print(sample_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = np.reshape(train_labels,(validation_cutoff,data_shape,8))\n",
    "test_labels = np.reshape(test_labels,(num_files-validation_cutoff,data_shape,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = np.zeros(8)\n",
    "count = np.sum(train_labels==1,axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# His are floats\n",
    "new_count = np.zeros(8)\n",
    "for i in range(8):\n",
    "    new_count[i] = float(count[i])\n",
    "#     print(new_count[i])\n",
    "count = new_count\n",
    "for i in range(8):\n",
    "    print(count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(check_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod_dir = \"/home/sim/notebooks/relaynet_pytorch/models/Denoised\" # Using the best denoised model\n",
    "mod = mod_dir + \"/bm3d_bs_40_ep_140.hdf5\"\n",
    "print(mod)\n",
    "x = model.load_weights(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Making only last layer trainable\n",
    "# for layer in model.layers[:-1]:\n",
    "for layer in model.layers[:18]:\n",
    "    layer.trainable = False\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(\"The {} Layer: {} :---- Is Trainable: {}\".format(i, layer, layer.trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(k,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrs = [0.01]\n",
    "bs = 40\n",
    "epoch = 40\n",
    "\n",
    "# Normalised Test\n",
    "# named = \"models/Normalised/raw_bs_{}_ep_{}\".format(bs,epoch)\n",
    "# named = \"models/Normalised/normalised_bs_{}_ep_{}\".format(bs,epoch)\n",
    "\n",
    "# Kernel Test\n",
    "# named = \"models/Kernel/ks{}{}_bs_{}_ep_{}\".format(k,s,bs,epoch).replace('.','_')\n",
    "\n",
    "# Weights Test\n",
    "# named = \"models/Weights/p4r8g11mag6bs_{}_ep_{}\".format(bs,epoch)\n",
    "\n",
    "# Epochs Test\n",
    "# epoch=120\n",
    "# named = \"models/Epochs/normalised_bs_{}_ep_{}\".format(bs,epoch)\n",
    "\n",
    "# Denoised Test\n",
    "# named = \"models/Denoised/\"+\"brushlet_enhanced\"+\"_bs_{}_ep_{}\".format(bs,epoch)\n",
    "# named = \"models/Denoised/\"+\"brushlet_denoised\"+\"_bs_{}_ep_{}\".format(bs,epoch)\n",
    "# named = \"models/Denoised/\"+\"bm3d\"+\"_bs_{}_ep_{}\".format(bs,epoch)\n",
    "# named = \"models/Denoised/\"+\"nl_means\"+\"_bs_{}_ep_{}\".format(bs,epoch)\n",
    "# named = \"models/Denoised/\"+\"bilateal_filter\"+\"_bs_{}_ep_{}\".format(bs,epoch)\n",
    "\n",
    "# Denoised Test\n",
    "# named = \"models/Dataset/\"+\"atrium\"+\"_bs_{}_ep_{}\".format(bs,epoch)\n",
    "# named = \"models/Dataset/\"+\"ventricle\"+\"_bs_{}_ep_{}\".format(bs,epoch)\n",
    "\n",
    "# Transfer Learning Test\n",
    "# named = \"models/TL/3lastconvs_conv2d__bs_{}_ep_{}_lr_{}\".format(bs,epoch,str(lrs[0]).replace('.','_')) # 18 layers means last 3 convolutions\n",
    "# for layer in model.layers[:18]:\n",
    "#     layer.trainable = False\n",
    "# named = \"models/TL/last2convs_conv2d__bs_{}_ep_{}_lr_{}\".format(bs,epoch,str(lrs[0]).replace('.','_')) #23 layers onwards\n",
    "# for layer in model.layers[:23]:\n",
    "#     layer.trainable = False\n",
    "named = \"models/TL/lastconv_conv2d__bs_{}_ep_{}_lr_{}\".format(bs,epoch,str(lrs[0]).replace('.','_')) # 18 layers means last 2 convolutions\n",
    "for layer in model.layers[:28]:\n",
    "    layer.trainable = False\n",
    "# named = \"models/TL/softmax__bs_{}_ep_{}_lr_{}\".format(bs,epoch,str(lrs[0]).replace('.','_')) # 18 layers means last 2 convolutions\n",
    "# for layer in model.layers[:-1]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "print(named)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in lrs:\n",
    "    # LR Test\n",
    "#     name_i = str(i).replace('.',\"_\")\n",
    "#     named = \"models/TL/softmax_conv2d__bs_{}_ep_{}_lr_{}\".format(bs,epoch,name_i)\n",
    "    \n",
    "    optimiser = optimizers.Adam(lr = i)\n",
    "    model.compile(optimizer=optimiser,loss=customized_loss,metrics=['accuracy',dice_coef],sample_weight_mode='temporal')\n",
    "    \n",
    "    #Defining Callback functions which will be called by model during runtime when specified condition satisfies\n",
    "    saved_name = named\n",
    "    lr_reducer = ReduceLROnPlateau(factor=0.5, cooldown=0, patience=6, min_lr=0.5e-6)\n",
    "    csv_logger = CSVLogger(saved_name+'.csv')\n",
    "    model_chekpoint = ModelCheckpoint(saved_name+\".hdf5\",monitor = 'val_loss',verbose = 1,save_best_only=True)\n",
    "    print('================'+str(i)+'===================')\n",
    "    model.fit(train_images,train_labels,batch_size=bs,epochs=epoch,validation_data=(test_images,test_labels),sample_weight=sample_weights,callbacks=[lr_reducer,csv_logger,model_chekpoint])\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF GPU",
   "language": "python",
   "name": "gputf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
