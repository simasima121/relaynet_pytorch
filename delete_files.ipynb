{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pprint\n",
    "import cv2\n",
    "from scipy.misc import imsave\n",
    "from helper import *\n",
    "import re\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text) : \n",
    "    return int(text) if text.isdigit() else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_keys(text) :\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_files(directory):\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    all_labels_files = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "    all_labels_files.sort()\n",
    "    return all_labels_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_list = ['H1_N01848_LA_1_272', 'H1_N01848_LA_1_388', 'H1_N01848_LV_1_194', 'H1_N01848_LV_1_300', 'H1_N01848_RVS_1_244', 'H1_N01848_RVS_1_300', 'H2_N02047_LA_1_241', 'H2_N02047_LA_1_257', 'H2_N02047_LVS_1_400', 'H2_N02047_LVS_1_420', 'H2_N02047_LV_1_194', 'H2_N02047_LV_1_400', 'H2_N02047_RA_1_380', 'H2_N02047_RA_1_400', 'H2_N02047_RVS_1_334', 'H2_N02047_RVS_1_400', 'H3_N02186_LA_1_400', 'H3_N02186_LA_1_416', 'H3_N02186_LVS_1_265', 'H3_N02186_LVS_1_676', 'H3_N02186_RA_1_380', 'H3_N02186_RA_1_400', 'H3_N02186_RVS_1_400', 'H3_N02186_RVS_1_420', 'H3_N02186_RV_1_270', 'H3_N02186_RV_1_400', 'H4_N03210_LVS_1_390', 'H4_N03210_LVS_1_400', 'H4_N03210_LV_1_400', 'H4_N03210_RA_1_400', 'H4_N03210_RA_1_440', 'H4_N03210_RVS_1_400', 'H4_N03210_RVS_1_420', 'H4_N03210_RV_1_390', 'H4_N03210_RV_1_400', 'H5_N03290_LA_1_380', 'H5_N03290_LA_1_400', 'H5_N03290_LVS_1_361', 'H5_N03290_LVS_1_400', 'H5_N03290_LV_1_400', 'H5_N03290_LV_1_420', 'H5_N03290_RVS_1_185', 'H5_N03290_RVS_1_400', 'H6_N03320_LA_1_391', 'H6_N03320_LA_1_450', 'H6_N03320_LVS_1_400', 'H6_N03320_LVS_1_455', 'H6_N03320_LV_1_404', 'H6_N03320_LV_1_620', 'H6_N03320_RA_1_420', 'H6_N03320_RVS_1_400', 'H6_N03320_RVS_1_476', 'H7_N03555_LVS_1_306', 'H7_N03555_LV_1_240', 'H7_N03555_RA_1_302', 'H7_N03555_RVS_1_41', 'H7_N03555_RV_1_221', 'H8_N03585_RA_1_345', 'H8_N03585_RVS_1_398', 'H9_N03857_LVS_1_420', 'H9_N03857_LV_1_580', 'H9_N03857_RVS_1_400', 'H9_N03857_RVS_1_420', 'H9_N03857_RV_1_380', 'H9_N03857_RV_1_425']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Unwanted Files\n",
    "atrium_files = []\n",
    "ventricle_files = []\n",
    "pruned_files = ['con_H1_N01848_LV_1_194.tif','con_H1_N01848_LV_1_300.tif','con_H2_N02047_LVS_1_400.tif','con_H2_N02047_LVS_1_420.tif','con_H3_N02186_LVS_1_265.tif','con_H3_N02186_RV_1_270.tif','con_H3_N02186_RV_1_400.tif','con_H4_N03210_LV_1_400.tif','con_H4_N03210_RV_1_390.tif','con_H4_N03210_RV_1_400.tif','con_H5_N03290_LV_1_420.tif','con_H6_N03320_LVS_1_455.tif','con_H6_N03320_LV_1_404.tif','con_H6_N03320_RA_1_420.tif','con_H8_N03585_RA_1_345.tif']\n",
    "pruned_files = [x.replace('con_','') for x in pruned_files]\n",
    "\n",
    "# for count, i in enumerate(new_file_list):\n",
    "#     print(count,i)\n",
    "# print(pruned_files)\n",
    "for files in new_file_list:\n",
    "    if files[11] == 'V':\n",
    "        ventricle_files.append(files)\n",
    "    elif files[11] == 'A':\n",
    "        atrium_files.append(files)\n",
    "# print(atrium_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_files_atrium(mydir, ext):\n",
    "    filelist = [ f for f in os.listdir(mydir) if f.endswith(ext) ]\n",
    "    \n",
    "#     print(len(filelist))\n",
    "    for f in filelist:\n",
    "        if f[:4] == 'con_':\n",
    "            new_f = f[4:]\n",
    "        elif f[:6] == 'label_':\n",
    "            new_f = f[6:]\n",
    "        elif f[:7] == 'weight_':\n",
    "            new_f = f[7:]\n",
    "        elif f[:3] == 'id_':\n",
    "            new_f = f[3:]\n",
    "        else:\n",
    "            new_f = f\n",
    "        if new_f[11] == 'V':\n",
    "            os.remove(os.path.join(mydir, f))\n",
    "\n",
    "def remove_files_ventricle(mydir, ext):\n",
    "    filelist = [ f for f in os.listdir(mydir) if f.endswith(ext) ]\n",
    "#     print(len(filelist))\n",
    "    for f in filelist:\n",
    "        if f[:4] == 'con_':\n",
    "            new_f = f[4:]\n",
    "        elif f[:6] == 'label_':\n",
    "            new_f = f[6:]\n",
    "        elif f[:7] == 'weight_':\n",
    "            new_f = f[7:]\n",
    "        elif f[:3] == 'id_':\n",
    "            new_f = f[3:]\n",
    "        else:\n",
    "            new_f = f\n",
    "\n",
    "        if new_f[11] == 'A':\n",
    "            os.remove(os.path.join(mydir, f))\n",
    "\n",
    "def remove_files_pruned(mydir, ext):\n",
    "    filelist = [ f for f in os.listdir(mydir) if f.endswith(ext) ]\n",
    "    hated_files = []\n",
    "    for f in filelist:\n",
    "        if f[:4] == 'con_':\n",
    "            new_f = f[4:]\n",
    "        elif f[:6] == 'label_':\n",
    "            new_f = f[6:]\n",
    "        elif f[:7] == 'weight_':\n",
    "            new_f = f[7:]\n",
    "        elif f[:3] == 'id_':\n",
    "            new_f = f[3:]\n",
    "        else:\n",
    "            new_f = f\n",
    "        for x in pruned_files:\n",
    "             if x[:19].replace('.','_') == new_f[:19].replace('.','_'):\n",
    "                os.remove(os.path.join(mydir, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Files from Pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the directories\n",
    "import os\n",
    "cwd = os.getcwd() + '/datasets-24-aug/OCTData/pruned/'\n",
    "\n",
    "print(cwd)\n",
    "directories = sorted(os.listdir(path=cwd))\n",
    "directories = directories[1:]\n",
    "\n",
    "# Standard folder\n",
    "folders = {}\n",
    "for i in directories:\n",
    "    name = i+'_folder'\n",
    "    folders[name] = cwd + i+'/'\n",
    "print('Name: {}\\nDirectory: {}\\n'.format('whole_raw_image_folder', folders['whole_raw_image_folder']))\n",
    "\n",
    "# Train folder\n",
    "train_folders = {}\n",
    "for i in directories:\n",
    "    name = i\n",
    "    train_folders[name] = cwd + i+'/Train/'\n",
    "\n",
    "# Transpose folder\n",
    "transpose_folders = {}\n",
    "for i in directories:\n",
    "    name = i\n",
    "    if os.path.exists(cwd + i+'/transpose/'):\n",
    "        transpose_folders[name] = cwd + i+'/transpose/'\n",
    "\n",
    "# Train/weight folder\n",
    "weight_folders = {}\n",
    "for i in directories:\n",
    "    name = i\n",
    "    if os.path.exists(cwd + i+'/Train/weights/'):\n",
    "        weight_folders[name] = cwd + i+'/Train/weights/'\n",
    "    \n",
    "# Train/segmented_ids folder\n",
    "id_folders = {}\n",
    "for i in directories:\n",
    "    name = i\n",
    "    if os.path.exists(cwd + i+'/Train/segmented_ids/'):\n",
    "        id_folders[name] = cwd + i+'/Train/segmented_ids/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard folder - .tif\n",
    "for folder in folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_pruned(folders[folder],ext)\n",
    "\n",
    "# Train folder - .tif\n",
    "# train_folders = {}\n",
    "for folder in train_folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_pruned(train_folders[folder],ext)\n",
    "\n",
    "# Transpose folder\n",
    "# transpose_folders = {}\n",
    "for folder in transpose_folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_pruned(transpose_folders[folder],ext)\n",
    "\n",
    "# Train/weight folder\n",
    "# weight_folders = {}\n",
    "for folder in weight_folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_pruned(weight_folders[folder],ext)\n",
    "\n",
    "# Train/segmented_ids folder\n",
    "# id_folders = {}\n",
    "for folder in id_folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_pruned(id_folders[folder],ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove files from Atrium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting the directories\n",
    "import os\n",
    "cwd = os.getcwd() + '/datasets-24-aug/OCTData/Atrium/'\n",
    "\n",
    "print(cwd)\n",
    "directories = sorted(os.listdir(path=cwd))\n",
    "directories = directories[1:]\n",
    "\n",
    "# Standard folder\n",
    "folders = {}\n",
    "for i in directories:\n",
    "    name = i+'_folder'\n",
    "    folders[name] = cwd + i+'/'\n",
    "print('Name: {}\\nDirectory: {}\\n'.format('whole_raw_image_folder', folders['whole_raw_image_folder']))\n",
    "\n",
    "# Train folder\n",
    "train_folders = {}\n",
    "for i in directories:\n",
    "    name = i\n",
    "    train_folders[name] = cwd + i+'/Train/'\n",
    "\n",
    "# Transpose folder\n",
    "transpose_folders = {}\n",
    "for i in directories:\n",
    "    name = i\n",
    "    if os.path.exists(cwd + i+'/transpose/'):\n",
    "        transpose_folders[name] = cwd + i+'/transpose/'\n",
    "\n",
    "# Train/weight folder\n",
    "weight_folders = {}\n",
    "for i in directories:\n",
    "    name = i\n",
    "    if os.path.exists(cwd + i+'/Train/weights/'):\n",
    "        weight_folders[name] = cwd + i+'/Train/weights/'\n",
    "    \n",
    "# Train/segmented_ids folder\n",
    "id_folders = {}\n",
    "for i in directories:\n",
    "    name = i\n",
    "    if os.path.exists(cwd + i+'/Train/segmented_ids/'):\n",
    "        id_folders[name] = cwd + i+'/Train/segmented_ids/'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard folder - .tif\n",
    "for folder in folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_atrium(folders[folder],ext)\n",
    "\n",
    "# Train folder - .tif\n",
    "# train_folders = {}\n",
    "for folder in train_folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_atrium(train_folders[folder],ext)\n",
    "\n",
    "# Transpose folder\n",
    "# transpose_folders = {}\n",
    "for folder in transpose_folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_atrium(transpose_folders[folder],ext)\n",
    "\n",
    "# Train/weight folder\n",
    "# weight_folders = {}\n",
    "for folder in weight_folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_atrium(weight_folders[folder],ext)\n",
    "\n",
    "# Train/segmented_ids folder\n",
    "# id_folders = {}\n",
    "for folder in id_folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_atrium(id_folders[folder],ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove files from ventricle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the directories\n",
    "import os\n",
    "cwd = os.getcwd() + '/datasets-24-aug/OCTData/Ventricle/'\n",
    "\n",
    "print(cwd)\n",
    "directories = sorted(os.listdir(path=cwd))\n",
    "directories = directories[1:]\n",
    "\n",
    "# Standard folder\n",
    "folders = {}\n",
    "for i in directories:\n",
    "    name = i+'_folder'\n",
    "    folders[name] = cwd + i+'/'\n",
    "print('Name: {}\\nDirectory: {}\\n'.format('whole_raw_image_folder', folders['whole_raw_image_folder']))\n",
    "\n",
    "# Train folder\n",
    "train_folders = {}\n",
    "for i in directories:\n",
    "    name = i\n",
    "    train_folders[name] = cwd + i+'/Train/'\n",
    "\n",
    "# Transpose folder\n",
    "transpose_folders = {}\n",
    "for i in directories:\n",
    "    name = i\n",
    "    if os.path.exists(cwd + i+'/transpose/'):\n",
    "        transpose_folders[name] = cwd + i+'/transpose/'\n",
    "\n",
    "# Train/weight folder\n",
    "weight_folders = {}\n",
    "for i in directories:\n",
    "    name = i\n",
    "    if os.path.exists(cwd + i+'/Train/weights/'):\n",
    "        weight_folders[name] = cwd + i+'/Train/weights/'\n",
    "    \n",
    "# Train/segmented_ids folder\n",
    "id_folders = {}\n",
    "for i in directories:\n",
    "    name = i\n",
    "    if os.path.exists(cwd + i+'/Train/segmented_ids/'):\n",
    "        id_folders[name] = cwd + i+'/Train/segmented_ids/'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard folder - .tif\n",
    "for folder in folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_ventricle(folders[folder],ext)\n",
    "\n",
    "# Train folder - .tif\n",
    "# train_folders = {}\n",
    "for folder in train_folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_ventricle(train_folders[folder],ext)\n",
    "\n",
    "# Transpose folder\n",
    "# transpose_folders = {}\n",
    "for folder in transpose_folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_ventricle(transpose_folders[folder],ext)\n",
    "\n",
    "# Train/weight folder\n",
    "# weight_folders = {}\n",
    "for folder in weight_folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_ventricle(weight_folders[folder],ext)\n",
    "\n",
    "# Train/segmented_ids folder\n",
    "# id_folders = {}\n",
    "for folder in id_folders: \n",
    "    for ext in ['.tif', '.jpg', '.JPG', '.png', '.npy']:\n",
    "        remove_files_ventricle(id_folders[folder],ext)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
