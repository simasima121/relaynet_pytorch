{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pprint\n",
    "import cv2\n",
    "from scipy.misc import imsave\n",
    "from helper import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the directories\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "main_direct = '/datasets/OCTData/Atrium/'\n",
    "directory = cwd + main_direct # main directory\n",
    "# Extensions\n",
    "raw_ext = '.tif'\n",
    "label_ext = '.JPG'\n",
    "\n",
    "files = {}\n",
    "for number, filename in enumerate(sorted(os.listdir(directory)), start=1):\n",
    "    files[number] = filename\n",
    "#     print(files[number])\n",
    "\n",
    "sub_directory = directory+files[2]+'/'\n",
    "print(sub_directory)\n",
    "\n",
    "image = plt.imread(sub_directory+'con_'+files[2]+raw_ext)\n",
    "# show_main_image(image)\n",
    "label_image = plt.imread(sub_directory+'label_'+files[2]+label_ext)\n",
    "# show_main_image(label_image)\n",
    "\n",
    "\n",
    "# Testing images saved correctly\n",
    "# test_raw = \"/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/Atrium/H1_N01848_LA_1_272/Resized_train/con_H1_N01848_LA_1_272_1.tif\"\n",
    "# test_label = \"/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/Atrium/H1_N01848_LA_1_272/Resized_train/label_H1_N01848_LA_1_272_1.JPG\"\n",
    "# test_colour = \"/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/Atrium/H1_N01848_LA_1_272/Resized_train/label_H1_N01848_LA_1_272_colour_1.JPG\"\n",
    "# test_weight = np.load('/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/Atrium/H1_N01848_LA_1_272/Resized_train/label_H1_N01848_LA_1_272_weight_1.npy')\n",
    "\n",
    "# image_raw = plt.imread(test_raw)\n",
    "# image_label = plt.imread(test_label)\n",
    "# image_colour = plt.imread(test_colour)\n",
    "# print(image_raw.shape)\n",
    "# print(image_label.shape)\n",
    "# print(image_colour.shape)\n",
    "\n",
    "# show_main_image(image_raw)\n",
    "# show_main_image(image_label)\n",
    "# show_main_image(image_colour)\n",
    "# show_main_image(test_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename Labelled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename files in folder\n",
    "rename = False\n",
    "\n",
    "if rename:\n",
    "    for number, filename in sorted(files.items()):\n",
    "        sub_directory = directory+files[number]+'/'\n",
    "        for f in os.listdir(sub_directory):\n",
    "            ext = f[-4:]\n",
    "            if ext == label_ext:\n",
    "                print(sub_directory)\n",
    "                old_filename = sub_directory+f\n",
    "                new_filename = sub_directory+'label_'+filename+label_ext\n",
    "                print(\"Old Filename: {}, New Filename: {}\".format(old_filename, new_filename))\n",
    "                os.rename(old_filename, new_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create New Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only have 19 atriums - need to create more segments of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_new_directory = False\n",
    "if make_new_directory:\n",
    "    for number, filename in sorted(files.items()):\n",
    "        sub_directory = directory+files[number]+'/'\n",
    "        for f in os.listdir(sub_directory):\n",
    "            ext = f[-4:]\n",
    "            # If the file isn't an ipynb notebook file and it's the .tif file\n",
    "            if ext == raw_ext:\n",
    "                path = sub_directory+'Resized_train'\n",
    "                os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Helper functions to find colours in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rgb(color):\n",
    "    r,g,b = color\n",
    "    return (int(r),int(g),int(b))\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/9694165/convert-rgb-color-to-english-color-name-like-green-with-python\n",
    "def closest_colour(requested_colour):\n",
    "    min_colours = {}\n",
    "    for key, name in wb.css3_hex_to_names.items():\n",
    "        r_c, g_c, b_c = wb.hex_to_rgb(key)\n",
    "        rd = (r_c - requested_colour[0]) ** 2\n",
    "        gd = (g_c - requested_colour[1]) ** 2\n",
    "        bd = (b_c - requested_colour[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]\n",
    "\n",
    "def get_colour_name(requested_colour):\n",
    "    try:\n",
    "        closest_name = actual_name = wb.rgb_to_name(requested_colour)\n",
    "    except ValueError:\n",
    "        closest_name = closest_colour(requested_colour)\n",
    "        actual_name = None\n",
    "    return actual_name, closest_name\n",
    "\n",
    "# Source Source: https://stackoverflow.com/questions/45043617/count-the-number-of-objects-of-different-colors-in-an-image-in-python\n",
    "def find_colors(file_name):\n",
    "    from skimage import io, morphology, measure\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    img = io.imread(file_name)\n",
    "\n",
    "    rows, cols, bands = img.shape\n",
    "    X = img.reshape(rows*cols, bands)\n",
    "\n",
    "\n",
    "    kmeans = KMeans(n_clusters=6, random_state=0).fit(X)\n",
    "    labels = kmeans.labels_.reshape(rows, cols)\n",
    "\n",
    "    for i in np.unique(labels):\n",
    "        blobs = np.int_(morphology.binary_opening(labels == i))\n",
    "        color = np.around(kmeans.cluster_centers_[i])\n",
    "        actual_name, closest_name = get_colour_name(to_rgb(color))\n",
    "        count = len(np.unique(measure.label(blobs))) - 1\n",
    "        \n",
    "        print('Color: {}, RGB: {}  >>  Objects: {}'.format(closest_name,color, count))\n",
    "        \n",
    "def pixel_colors(file_name):\n",
    "    '''\n",
    "    Creating a dictionary of colours to see what colors are in images.\n",
    "    '''\n",
    "    from skimage import io\n",
    "    if type(file_name) == str:\n",
    "        img = io.imread(file_name)\n",
    "    else:\n",
    "        img = file_name\n",
    "    \n",
    "    new_img = np.copy(img)\n",
    "    rows, cols, bands = new_img.shape\n",
    "    \n",
    "    dict_of_colours = {}\n",
    "    for row in range(150,350):\n",
    "        if row % 25 == 0:\n",
    "            print(row)\n",
    "        for col in range(0,50):\n",
    "            pixel_color = new_img[row][col]\n",
    "            actual, close = get_colour_name(pixel_color)\n",
    "            if actual != None:\n",
    "                if actual in dict_of_colours:\n",
    "                    dict_of_colours[actual] += 1\n",
    "                else:\n",
    "                    dict_of_colours[actual] = 1\n",
    "                list_of_colors.add(actual)\n",
    "            else:\n",
    "                if close in dict_of_colours:\n",
    "                    dict_of_colours[close] += 1\n",
    "                else:\n",
    "                    dict_of_colours[close] = 1\n",
    "\n",
    "    return dict_of_colours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Colours/id of a class\n",
    "https://www.w3schools.com/colors/colors_picker.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webcolors as wb\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.color import rgb2lab, deltaE_cie76\n",
    "from PIL import Image\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/44428315/similar-color-detection-in-python\n",
    "\n",
    "# Blurring image \n",
    "def blur_image(img, b):\n",
    "    if b == \"average\":\n",
    "        kernel = np.ones((3,6),np.float32)/25\n",
    "        blurred = cv2.filter2D(img,-1,kernel)\n",
    "    elif b == \"gaussian\":\n",
    "    # Gaussian Blur\n",
    "        blur=cv2.GaussianBlur(img,(13,13),0)\n",
    "        blurred=cv2.cvtColor(blur,cv2.COLOR_BGR2HSV)\n",
    "    elif b == \"bilateral\":\n",
    "    # Bilaterial Filter\n",
    "        blur=cv2.bilateralFilter(img,5,25,25)\n",
    "        blurred=cv2.cvtColor(blur,cv2.COLOR_BGR2HSV)\n",
    "    return blurred\n",
    "\n",
    "def turn_array(rgb):\n",
    "    '''\n",
    "    turn rgb into np.array\n",
    "    '''\n",
    "    return np.uint8(np.asarray([[rgb]]))\n",
    "\n",
    "def turn_rgb_2_lab(color, lab):\n",
    "    '''\n",
    "    Convert RGB to CIE 1976 L*a*b*\n",
    "    '''\n",
    "    return deltaE_cie76(rgb2lab(color),lab)\n",
    "\n",
    "def rgb_to_id(rgb, threshold, color, ids, lab):\n",
    "    '''\n",
    "    Convert rgb to id\n",
    "    '''\n",
    "#     print(get_colour_name(color), color, ids)\n",
    "    color_3d = turn_array(color)\n",
    "    dE_color = turn_rgb_2_lab(color_3d, lab)\n",
    "    rgb[dE_color < threshold] = ids\n",
    "\n",
    "    return rgb\n",
    "\n",
    "def ref_colour(rgb):\n",
    "    '''\n",
    "    Finding colours within a range of the colour input\n",
    "    input = pixel\n",
    "    '''\n",
    "#     rgb = io.imread('https://i.stack.imgur.com/npnrv.png') # to show where the images overlap\n",
    "    new_rgb = np.copy(rgb)\n",
    "    \n",
    "    lab = rgb2lab(new_rgb)\n",
    "    \n",
    "    threshold = 15  \n",
    "    \n",
    "    # Lime and limegreen is same as Green \n",
    "    green = [0,128,0]\n",
    "    lime = [0,255,0]\n",
    "    limegreen = [50, 205, 50]\n",
    "    \n",
    "    rgb_to_id(new_rgb, threshold, green, 0, lab)\n",
    "    rgb_to_id(new_rgb, threshold, lime, 0, lab)\n",
    "    rgb_to_id(new_rgb, threshold, limegreen, 0, lab)\n",
    "    \n",
    "    # Orange is same as dark orange\n",
    "    orange = [255, 165, 0]\n",
    "    darkorange = [255, 140, 0]\n",
    "    chocolate = [180,101,24]\n",
    "    \n",
    "    rgb_to_id(new_rgb, threshold, orange, 1, lab)\n",
    "    rgb_to_id(new_rgb, threshold, darkorange, 1, lab)\n",
    "    rgb_to_id(new_rgb, threshold, chocolate, 1, lab)\n",
    "    \n",
    "    # Dark Violet = Purple = Medium Purple = Darkorchid\n",
    "    purple = [128,0,128]\n",
    "    darkviolet = [177,10,255]\n",
    "    mediumpurple = [147, 112, 219]\n",
    "    darkorchid = [153, 50, 204]\n",
    "    \n",
    "    rgb_to_id(new_rgb, threshold, purple, 2, lab)\n",
    "    rgb_to_id(new_rgb, threshold, darkviolet, 2, lab)\n",
    "    rgb_to_id(new_rgb, threshold, mediumpurple, 2, lab)\n",
    "    rgb_to_id(new_rgb, threshold, darkorchid, 2, lab)\n",
    "    \n",
    "    # Magenta/Fuschia\n",
    "    magenta = [255,0,255]\n",
    "    darkmagenta = [139, 0, 139]\n",
    "    \n",
    "    magenta_threshold = 20\n",
    "    \n",
    "    rgb_to_id(new_rgb, magenta_threshold, magenta, 3, lab)\n",
    "    rgb_to_id(new_rgb, magenta_threshold, darkmagenta, 3, lab)\n",
    "    \n",
    "    # Blue\n",
    "    blue = [0, 0, 255]\n",
    "    darkslateblue = [72, 61, 139]\n",
    "    midnightblue = [25, 25, 112]\n",
    "    mediumblue = [0, 0, 205]\n",
    "    \n",
    "    rgb_to_id(new_rgb, threshold, blue, 4, lab)\n",
    "    rgb_to_id(new_rgb, threshold, darkslateblue, 4, lab)\n",
    "    rgb_to_id(new_rgb, threshold, midnightblue, 4, lab)\n",
    "    rgb_to_id(new_rgb, threshold, mediumblue, 4, lab)\n",
    "    \n",
    "    # Yellow = Gold\n",
    "    yellow = [255,255,0]\n",
    "    gold = [255, 215, 0]\n",
    "    goldenrod = [218, 165, 32]\n",
    "    goldenrod2 = [183,178,36]\n",
    "    darkgoldenrod = [184, 134, 11]\n",
    "    \n",
    "    rgb_to_id(new_rgb, threshold, yellow, 5, lab)\n",
    "    rgb_to_id(new_rgb, threshold, gold, 5, lab)\n",
    "    rgb_to_id(new_rgb, threshold, goldenrod, 5, lab)\n",
    "    rgb_to_id(new_rgb, threshold, goldenrod2, 5, lab)\n",
    "    rgb_to_id(new_rgb, threshold, darkgoldenrod, 5, lab)\n",
    "    \n",
    "    # Red = OrangeRed\n",
    "    red = [255,0,0]\n",
    "    orangered = [255, 69, 0]\n",
    "    firebrick = [181,17,17]\n",
    "    \n",
    "    rgb_to_id(new_rgb, threshold, red, 6, lab)\n",
    "    rgb_to_id(new_rgb, threshold, orangered, 6, lab)\n",
    "    rgb_to_id(new_rgb, threshold, firebrick, 6, lab)\n",
    "    \n",
    "    # Black = Grey \n",
    "    black = [0, 0, 0]\n",
    "    dimgrey = [105, 105, 105]\n",
    "    darkslategrey = [47, 79, 79]\n",
    "    lightgrey = [211, 211, 211]\n",
    "    gainsboro = [220, 220, 220]\n",
    "    grey = [128, 128, 128]\n",
    "    lightslategrey = [119, 136, 153]\n",
    "    darkgrey = [169, 169, 169]\n",
    "    \n",
    "    # NOTE: USED TO BE -1 BUT CHANGED AS VALUE NEEDED FOR CROSS ENTROPY - CAN'T HAVE 0\n",
    "    rgb_to_id(new_rgb, threshold, black, 7, lab)\n",
    "    rgb_to_id(new_rgb, threshold, dimgrey, 7, lab)\n",
    "    rgb_to_id(new_rgb, threshold, darkslategrey, 7, lab)\n",
    "    rgb_to_id(new_rgb, threshold, lightgrey, 7, lab)\n",
    "    rgb_to_id(new_rgb, threshold, gainsboro, 7, lab)\n",
    "    rgb_to_id(new_rgb, threshold, grey, 7, lab)\n",
    "    rgb_to_id(new_rgb, threshold, lightslategrey, 7, lab)\n",
    "    rgb_to_id(new_rgb, threshold, darkgrey, 7, lab)\n",
    "\n",
    "    new_grey = cv2.cvtColor( new_rgb, cv2.COLOR_RGB2GRAY ) # convert image to grayscale\n",
    "    \n",
    "    return new_grey\n",
    "\n",
    "def convert_to_id_image(image):\n",
    "    '''\n",
    "    convert rgb images to id\n",
    "    '''\n",
    "    returned_grey_image = ref_colour(image)\n",
    "    rows, cols = returned_grey_image.shape\n",
    "    g_y = np.copy(returned_grey_image)\n",
    "    for x in range(0, rows):\n",
    "        for j in range(0,cols):\n",
    "#             if returned_grey_image[x][j] > 7: # Setting values in the array to void if they're not in labels\n",
    "#                 returned_grey_image[x][j] = -1 # this created issue with cross_entropy\n",
    "            if returned_grey_image[x][j] > 6: # Setting values in the array to void if they're not in labels\n",
    "                g_y[x][j] = 7\n",
    "    print(np.unique(g_y))\n",
    "    return g_y\n",
    "\n",
    "def convert_to_rgb_image(id_image):\n",
    "    '''\n",
    "    Convert id back to rgb \n",
    "    '''\n",
    "    rows, cols = id_image.shape\n",
    "\n",
    "    lime = [0,255,0] # id = 0\n",
    "    darkorange = [255, 140, 0] # id = 1\n",
    "    darkviolet = [177,10,255] # id = 2\n",
    "    magenta = [255,0,255] # id = 3\n",
    "    blue = [0, 0, 255] # id = 4\n",
    "    yellow = [255, 255, 0] # id = 5\n",
    "    red = [255,0,0] # id = 6\n",
    "    black = [0, 0, 0]# id = 7\n",
    "    \n",
    "    colors = [ lime, darkorange, darkviolet, magenta, blue, yellow, red, black]\n",
    "    new_image = np.zeros((rows,cols,3))\n",
    "    for x in range(0, rows):\n",
    "        for j in range(0,cols):\n",
    "            pixel_value = int(id_image[x][j])\n",
    "            if pixel_value > 6: # Setting values in the array to black if they're not in labels\n",
    "                new_image[x][j] = black\n",
    "            else:\n",
    "                new_image[x][j] = colors[pixel_value] # setting id to colours - values between 0-6\n",
    "    return new_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blurred images produce worse results as can be seen in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_images(file_name):\n",
    "    '''\n",
    "    Display images from rgb to id back to rgb\n",
    "    \n",
    "    Returns id_image\n",
    "    '''\n",
    "    if type(file_name) == str:\n",
    "        image = plt.imread(file_name)\n",
    "    else:\n",
    "        image = file_name\n",
    "#     show_main_image(image)\n",
    "    id_image = convert_to_id_image(image)\n",
    "#     show_main_image(id_image)\n",
    "    rgb_image = convert_to_rgb_image(id_image)\n",
    "#     show_main_image(rgb_image)\n",
    "    return id_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_image = blur_image(label_image, 'gaussian')\n",
    "# pprint.pprint(pixel_colors(blurred_image))\n",
    "show_main_image(blurred_image)\n",
    "# atrium_folder = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/png_labels_atrium'\n",
    "# test_image = atrium_folder + '/label_H1_N01848_LA_1_272_labels.png'\n",
    "# test_image = plt.imread(test_image)\n",
    "# show_main_image(test_image)\n",
    "# rgb_image = convert_to_rgb_image(test_image)\n",
    "# show_main_image(rgb_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extensions\n",
    "raw_ext = '.tif'\n",
    "label_ext = '.JPG'\n",
    "\n",
    "files = {}\n",
    "for number, filename in enumerate(sorted(os.listdir(directory)), start=1):\n",
    "    files[number] = filename\n",
    "print(filename)\n",
    "for i in range(2,3):\n",
    "    type_of_heart = files[i][10:]\n",
    "    print(type_of_heart)\n",
    "    if type_of_heart[1:2] == 'A':\n",
    "        sub_directory = directory+files[i]+'/'\n",
    "        file_name = sub_directory+'label_'+files[i]+label_ext\n",
    "        print(file_name)\n",
    "        id_image = produce_images(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_main_image(id_image)\n",
    "# print(id_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Weighting algorithm to an image\n",
    "def weighting_algo(id_image):\n",
    "    '''\n",
    "    Creating weighting of an image\n",
    "    '''\n",
    "    image = id_image\n",
    "    x,y = image.shape\n",
    "    weighted_image = np.zeros((x,y))\n",
    "    for j in range(x):\n",
    "        for k in range(y):\n",
    "            # Setting weights for the image\n",
    "            if(image[j][k]==1):\n",
    "                w2 = 11.459\n",
    "            elif(image[j][k] == 2):\n",
    "                w2 = 5.63\n",
    "            elif(image[j][k]== 3):\n",
    "                w2 = 11.007 \n",
    "            elif(image[j][k] == 4):\n",
    "                w2 = 14.368 \n",
    "            elif(image[j][k]== 5):\n",
    "                w2 = 3.336 \n",
    "            elif(image[j][k]== 6):\n",
    "                w2 = 13.647 \n",
    "            elif(image[j][k]== 7):\n",
    "                w2 = 16.978 \n",
    "            else:\n",
    "                w2 = 0\n",
    "#             if(image[j][k]==0):\n",
    "#                 w2 = 5\n",
    "#             elif(image[j][k] == 1):\n",
    "#                 w2 = 5\n",
    "#             elif(image[j][k]== 2):\n",
    "#                 w2 = 5 \n",
    "#             elif(image[j][k] == 3):\n",
    "#                 w2 = 5 \n",
    "#             elif(image[j][k]== 4):\n",
    "#                 w2 = 5 \n",
    "#             elif(image[j][k]== 5):\n",
    "#                 w2 = 5 \n",
    "#             elif(image[j][k]== 6):\n",
    "#                 w2 = 5 \n",
    "#             else:\n",
    "#                 w2 = 0\n",
    "            if(j!=0 and j!=x-1):\n",
    "                next_pix = image[j+1][k]\n",
    "                prev_pix = image[j-1][k]\n",
    "                # Taking the derivative of the pixels\n",
    "                if((next_pix-prev_pix)>0 and w2!=0):\n",
    "                    w1 = 10  \n",
    "                else:\n",
    "                    w1 = 0\n",
    "            else:\n",
    "                w1 = 0\n",
    "            w = 1 + w1 + w2\n",
    "            weighted_image[j][k] = w\n",
    "    return weighted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_image = weighting_algo(id_image)\n",
    "# show_main_image(weighted_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_directory = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/Atrium/H1_N01848_LA_1_272/'\n",
    "# word = 'label_H1_N01848_LA_1_272.JPG'\n",
    "# ext = '.JPG'\n",
    "# i = 0\n",
    "# save_np_array(weighted_image, sub_directory, word, ext, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save segmented images and weighted images.\n",
    "def save_all(segmented_image, sub_directory, word, ext, i):\n",
    "    \n",
    "    # saving colour segmented image\n",
    "    save_image(segmented_image, sub_directory, word, ext, i, True)\n",
    "                        \n",
    "    # converting colour segmented image into image id   \n",
    "    id_image = produce_images(segmented_image) \n",
    "\n",
    "    # convert image_id into weighted image \n",
    "    weighted_image = weighting_algo(id_image)\n",
    "    \n",
    "    # making sure shap of np array is correct\n",
    "    h,w = id_image.shape\n",
    "    if h != 512 or w != 64:\n",
    "        amount = 512 - h\n",
    "        weight_full = np.full((amount, 64), 1)\n",
    "        id_full = np.full((amount, 64), 255)\n",
    "        new_weighted_image = np.concatenate((weighted_image, weight_full))\n",
    "        new_id_image = np.concatenate((id_image, id_full))\n",
    "        print(new_id_image.shape)\n",
    "        save_np_array(new_id_image, sub_directory, word, ext, i, True)\n",
    "        save_np_array(new_weighted_image, sub_directory, word, ext, i)\n",
    "    else:\n",
    "        # saving as np array \n",
    "        save_np_array(id_image, sub_directory, word, ext, i, True)\n",
    "        save_np_array(weighted_image, sub_directory, word, ext, i)\n",
    "    \n",
    "#     show_main_image(weighted_image)\n",
    "    \n",
    "    print('saved_array',i+1)\n",
    "    \n",
    "    oct_image = rgb_to_grey(segmented_image) # convert image to greyscale\n",
    "    save_image(oct_image, sub_directory, word, ext, i, False) # only save_image because don't need the weighted array\n",
    "\n",
    "# Deleting wrongly named files\n",
    "for number, filename in sorted(files.items()):\n",
    "    if files[number][-2:] != 'h5':\n",
    "        sub_directory = directory+files[number]+'/Resized_train/'\n",
    "        for f in os.listdir(sub_directory):\n",
    "            ext = f[-4:]\n",
    "            if ext == '.npy' and f[-5:-4] == 't':\n",
    "                silentremove(sub_directory+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_segments = False\n",
    "\n",
    "if make_segments:\n",
    "    for number, filename in sorted(files.items()):\n",
    "        if files[number][-2:] == 'h5':\n",
    "            continue\n",
    "        \n",
    "        sub_directory = directory+files[number]+'/'\n",
    "        print(sub_directory)\n",
    "        for f in os.listdir(sub_directory):\n",
    "            ext = f[-4:]\n",
    "            shape = 2\n",
    "            print(f)\n",
    "            if ext == raw_ext or ext == label_ext:\n",
    "                image_file = sub_directory+f\n",
    "                image = plt.imread(image_file)\n",
    "                \n",
    "                # Crop all images\n",
    "                if len(image.shape) == 2:\n",
    "                    height, width = image.shape\n",
    "                    if width > 600:\n",
    "                        image = crop_image(image, 0, 600) # Crop all images at 512,600\n",
    "                elif len(image.shape) == 3:\n",
    "                    height, width, colour = image.shape\n",
    "                    if width > 600:\n",
    "                        image = crop_image(image, 0, 600, colour) # Crop all images at 512,600\n",
    "                \n",
    "                # Segment all iamges\n",
    "                segmented_images = segment_image(image, 0, 600, 64)\n",
    "                for i in range(len(segmented_images)):\n",
    "                    if len(image.shape) == 2:\n",
    "                        save_image(segmented_images[i], sub_directory, f, ext, i, False) # save_image because already raw image\n",
    "                    elif len(image.shape) == 3:\n",
    "                        save_all(segmented_images[i], sub_directory, f, ext, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Files into new folder\n",
    "atrium_folder = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/atrium_data/'\n",
    "raw_image_folder = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/whole_raw_image/'\n",
    "manual_label_folder = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/manual_label/'\n",
    "copy_files = False\n",
    "if copy_files:\n",
    "    from shutil import copy\n",
    "    for number, filename in sorted(files.items()):\n",
    "        if filename[-2:] != 'h5':\n",
    "            sub_directory = directory+files[number]+'/'\n",
    "            \n",
    "            # NOTE: Copying all files into manual and label folders\n",
    "            for f in os.listdir(sub_directory):\n",
    "                ext = f[-4:]\n",
    "                src = sub_directory+f\n",
    "                if ext == '.JPG':\n",
    "                    copy(src,manual_label_folder)\n",
    "                elif ext =='.tif':\n",
    "                    copy(src,raw_image_folder)\n",
    "#             if f == 'Resized_train':\n",
    "#                 resize_direct = sub_directory+f\n",
    "#                 for p in os.listdir(resize_direct):\n",
    "#                     \n",
    "#                     src = resize_direct+'/'+p\n",
    "#                     if ext == '.npy' or ext == '.tif':\n",
    "#                         copy(src,atrium_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing moving files was done correctly - it was "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce_images('/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/Atrium/H8_N03585_RA_1_345/label_H8_N03585_RA_1_345.JPG')\n",
    "# test_id = np.load(atrium_folder+'label_H8_N03585_RA_1_345_id_1.npy')\n",
    "\n",
    "# show_main_image(test_id)\n",
    "# rgb_image = convert_to_rgb_image(test_id)\n",
    "# show_main_image(rgb_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create IMDB of dataset - HP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "files_array = []\n",
    "folder_names = []\n",
    "for number, filename in sorted(files.items()):\n",
    "    if files[number][-2:] != 'h5':\n",
    "        sub_directory = directory+files[number]+'/Resized_train/'\n",
    "        folder_names.append(files[number]) # appending names of folder to list\n",
    "        no_files = len(fnmatch.filter(os.listdir(sub_directory), '*.tif'))\n",
    "        count = count + no_files\n",
    "H = 512\n",
    "W = 64\n",
    "N = count\n",
    "print(N)\n",
    "print(sub_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atrium_ids = cwd + '/datasets/OCTData/atrium_data/ids/'\n",
    "atrium_weights = cwd + '/datasets/OCTData/atrium_data/weights/'\n",
    "atrium_raw = cwd + '/datasets/OCTData/atrium_data/raw/'\n",
    "\n",
    "atrium_id_files = {}\n",
    "atrium_weights_files = {}\n",
    "atrium_raw_files = {}\n",
    "for number, filename in enumerate(sorted(os.listdir(atrium_ids)), start=1):\n",
    "    atrium_id_files[number] = filename\n",
    "for number, filename in enumerate(sorted(os.listdir(atrium_weights)), start=1):\n",
    "    atrium_weights_files[number] = filename\n",
    "for number, filename in enumerate(sorted(os.listdir(atrium_raw)), start=1):\n",
    "    atrium_raw_files[number] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_h5py_array(name, dictionary, count):\n",
    "    id_files = []\n",
    "    atr_direct = '/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/atrium_data/'\n",
    "\n",
    "    for number, filename in sorted(dictionary.items()):\n",
    "\n",
    "        sub_directory = atr_direct+name+'/'+dictionary[number]\n",
    "        if count == 163:\n",
    "            print(sub_directory)\n",
    "        if name == 'raw':\n",
    "            act_file = plt.imread(sub_directory)\n",
    "            act_file = np.array(act_file)\n",
    "        else:\n",
    "            act_file = np.load(sub_directory)\n",
    "        id_files.append(act_file)\n",
    "        count += 1\n",
    "    return id_files\n",
    "count = 0\n",
    "id_files = make_h5py_array('ids', atrium_id_files, count)\n",
    "count = 0\n",
    "weight_files = make_h5py_array('weights', atrium_weights_files, count)\n",
    "count = 0\n",
    "raw_files = make_h5py_array('raw', atrium_raw_files, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Creating Data.h5 File\n",
    "data = np.zeros((N,1, H, W))\n",
    "\n",
    "for i in range(N):\n",
    "    image = raw_files[i] # array of size (H,W)\n",
    "    for m in range(H):\n",
    "        for n in range(W):\n",
    "            data[i, 0, m, n] = image[m,n]\n",
    "    \n",
    "data = torch.from_numpy(data).float()\n",
    "print(data.shape)\n",
    "hf = h5py.File('/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/Data.h5', 'w')\n",
    "hf.create_dataset('data', data=data) # creating raw data dataset - group name followed by dimensions in [H,W,Channel,DataIndex]\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating label.h5 File\n",
    "labels = np.zeros((N,2, H, W))\n",
    "\n",
    "for i in range(N):\n",
    "    weights = weight_files[i] # array of size (H,W)\n",
    "    ids = id_files[i] # array of size (H,W) # class is your colour\n",
    "    \n",
    "    h,w = ids.shape\n",
    "    if h != 512 or w != 64:\n",
    "#         print(h,w)\n",
    "        amount = H - h\n",
    "        weight_full = np.full((amount, 64), 1.0)\n",
    "        id_full = np.full((amount, 64), 7)\n",
    "        weights = np.concatenate((weights, weight_full))\n",
    "        ids = np.concatenate((ids, id_full))   \n",
    "    new_id = np.copy(ids)\n",
    "    for m in range(H):\n",
    "        for n in range(W):\n",
    "            if ids[m,n] > 7:\n",
    "                # set all label values to 7 \n",
    "                new_id[m,n] = 7\n",
    "            labels[i, 0, m, n] = new_id[m,n]\n",
    "            labels[i, 1, m, n] = weights[m,n]\n",
    "\n",
    "labels = torch.from_numpy(labels).float()\n",
    "print(np.unique(labels[:,0,:,:]))\n",
    "print('Finalshape:',labels.shape)\n",
    "\n",
    "hf = h5py.File('/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/label.h5', 'w')\n",
    "hf.create_dataset('labels', data=labels) \n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating set.h5 File\n",
    "sets = np.ones((1,N))\n",
    "split = N * 0.8\n",
    "sets[:,int(split):] = 3\n",
    "\n",
    "hf = h5py.File('/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/set.h5', 'w')\n",
    "hf.create_dataset('set', data=sets)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
