{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pprint\n",
    "import cv2\n",
    "from scipy.misc import imsave\n",
    "from helper import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "# plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Lambda \n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Reshape\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import regularizers, optimizers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger,EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np    \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "from scipy.misc import imsave\n",
    "from scipy import ndimage, misc\n",
    "from numpy import unravel_index\n",
    "from operator import sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text) : \n",
    "    return int(text) if text.isdigit() else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_keys(text) :\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(filenames, ext):\n",
    "    images = []\n",
    "\n",
    "    for filename in filenames :\n",
    "        filepath = os.path.join(root,filename)\n",
    "        if ext == '.npy':\n",
    "            image = np.load(filepath)\n",
    "            h,w = image.shape\n",
    "            \n",
    "            if h != 512 or w != 64:\n",
    "#                 print(h,w) \n",
    "                amount = 512 - h\n",
    "                id_full = np.full((amount, 64), 0)\n",
    "                try:\n",
    "                    image = np.concatenate((image, id_full))\n",
    "                except Exception as e:\n",
    "                    print(image.shape)\n",
    "#                 print(image.shape)\n",
    "        elif ext == '.JPG' or ext == '.png':\n",
    "            image = ndimage.imread(filepath)\n",
    "        images.append(image)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Raw Images\n",
    "root_path = \"\"\n",
    "filenames = []\n",
    "for root, dirnames, filenames in os.walk(\"/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/alldata/whole_raw_image/Train\"):\n",
    "    filenames.sort(key = natural_keys)\n",
    "    rootpath = root\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filenames[128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images = get_info(filenames, '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(raw_images[0],cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (raw_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting manual labelled Images\n",
    "root_path = \"\"\n",
    "filenames = []\n",
    "for root, dirnames, filenames in os.walk(\"/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/alldata/manual_label/Train\"):\n",
    "    filenames.sort(key = natural_keys)\n",
    "    rootpath = root\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_labels = get_info(filenames, '.png')\n",
    "print (manual_labels[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(manual_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Labels\n",
    "root_path = \"\"\n",
    "filenames = []\n",
    "# for root, dirnames, filenames in os.walk(\"/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/alldata/labels_corrected/Train/segmented_ids\"):\n",
    "for root, dirnames, filenames in os.walk(\"/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/alldata/png_labels_method/Train/segmented_ids\"):\n",
    "    filenames.sort(key = natural_keys)\n",
    "    rootpath = root\n",
    "# print(len(filenames))\n",
    "labels_list = get_info(filenames, '.npy')\n",
    "print(labels_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ids in labels_list:\n",
    "    h,w = ids.shape\n",
    "    if h != 512 or w != 64:\n",
    "        print(h,w)\n",
    "print(np.unique(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.zeros((len(filenames),512,64,8))\n",
    "# train_labels = np.full((171,512,64,8),0.000\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 1\n",
    "for i in range(len(labels_list)) :\n",
    "    for j in range(512) :\n",
    "        for k in range(64):\n",
    "            if(labels_list[i][j][k] == 0):\n",
    "                train_labels[i][j][k][0] = val\n",
    "            if(labels_list[i][j][k] == 1):\n",
    "                train_labels[i][j][k][1] = val\n",
    "            if(labels_list[i][j][k] == 2):\n",
    "                train_labels[i][j][k][2] = val\n",
    "            if(labels_list[i][j][k] == 3):\n",
    "                train_labels[i][j][k][3] = val\n",
    "            if(labels_list[i][j][k] == 4):\n",
    "                train_labels[i][j][k][4] = val\n",
    "            if(labels_list[i][j][k] == 5):\n",
    "                train_labels[i][j][k][5] = val\n",
    "            if(labels_list[i][j][k] == 6):\n",
    "                train_labels[i][j][k][6] = val\n",
    "            if(labels_list[i][j][k] == 7):\n",
    "                train_labels[i][j][k][7] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=raw_images\n",
    "images=np.array(images)\n",
    "print(images.shape[0])\n",
    "images = images.reshape(images.shape[0],512,64,1)\n",
    "\n",
    "num_files = len(filenames)\n",
    "validation_cutoff = int(len(filenames)*0.8)\n",
    "\n",
    "# print(images[0].shape)\n",
    "train_indices = np.random.choice(num_files,validation_cutoff,replace = False)\n",
    "# print(train_indices)\n",
    "# print(sorted(train_indices))\n",
    "# print(train_labels[170])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_random = []\n",
    "train_labels_random = []\n",
    "\n",
    "for i in train_indices:\n",
    "    train_images_random.append(images[i])\n",
    "    train_labels_random.append(train_labels[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = [x for x in range(num_files) if x not in train_indices]\n",
    "print(test_indices)\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for i in test_indices:\n",
    "    test_images.append(images[i])\n",
    "    test_labels.append(train_labels[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images_random)\n",
    "train_labels = np.array(train_labels_random)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(train_images.shape, test_images.shape)\n",
    "print(train_labels.shape, test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32')\n",
    "train_labels = train_labels.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "test_labels = test_labels.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(train_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(train_images))\n",
    "print (len(train_labels))\n",
    "print (np.array(train_labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(np.rot90(train_images[0,:,:,0]), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"\"\n",
    "filenames = []\n",
    "# for root, dirnames, filenames in os.walk(\"/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/alldata/labels_corrected/Train/weights\"):\n",
    "for root, dirnames, filenames in os.walk(\"/home/sim/notebooks/relaynet_pytorch/datasets/OCTData/alldata/png_labels_method/Train/weights\"):\n",
    "    filenames.sort(key = natural_keys)\n",
    "    rootpath = root\n",
    "\n",
    "weights = get_info(filenames, '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(weights),weights[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix = []\n",
    "for i in train_indices:\n",
    "    weights_matrix.append(weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.array(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = 512*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.reshape(sample_weights,(validation_cutoff,data_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Defines the input tensor\n",
    "inputs = Input(shape=(512,64,1))\n",
    "\n",
    "L1 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(inputs)\n",
    "L2 = BatchNormalization()(L1)\n",
    "L2 = Activation('relu')(L2)\n",
    "#L3 = Lambda(maxpool_1,output_shape = shape)(L2)\n",
    "L3 = MaxPooling2D(pool_size=(2,2))(L2)\n",
    "L4 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L3)\n",
    "L5 = BatchNormalization()(L4)\n",
    "L5 = Activation('relu')(L5)\n",
    "#L6 = Lambda(maxpool_2,output_shape = shape)(L5)\n",
    "L6 = MaxPooling2D(pool_size=(2,2))(L5)\n",
    "L7 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L6)\n",
    "L8 = BatchNormalization()(L7)\n",
    "L8 = Activation('relu')(L8)\n",
    "#L9 = Lambda(maxpool_3,output_shape = shape)(L8)\n",
    "L9 = MaxPooling2D(pool_size=(2,2))(L8)\n",
    "L10 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L9)\n",
    "L11 = BatchNormalization()(L10)\n",
    "L11 = Activation('relu')(L11)\n",
    "L12 = UpSampling2D(size = (2,2))(L11)\n",
    "#L12 = Lambda(unpool_3,output_shape = unpool_shape)(L11)\n",
    "L13 = Concatenate(axis = 3)([L8,L12])\n",
    "L14 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L13)\n",
    "L15 = BatchNormalization()(L14)\n",
    "L15 = Activation('relu')(L15)\n",
    "L16 = UpSampling2D(size= (2,2))(L15)\n",
    "#L16 = Lambda(unpool_2,output_shape=unpool_shape)(L15)\n",
    "L17 = Concatenate(axis = 3)([L16,L5])\n",
    "L18 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L17)\n",
    "L19 = BatchNormalization()(L18)\n",
    "L19 = Activation('relu')(L19)\n",
    "#L20 = Lambda(unpool_1,output_shape=unpool_shape)(L19)\n",
    "L20 = UpSampling2D(size=(2,2),name = \"Layer19\")(L19)\n",
    "L21 = Concatenate(axis=3)([L20,L2])\n",
    "L22 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L21)\n",
    "L23 = BatchNormalization()(L22)\n",
    "L23 = Activation('relu')(L23)\n",
    "L24 = Conv2D(8,kernel_size=(1,1),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L23)\n",
    "L = Reshape((data_shape,8),input_shape = (512,64,8))(L24)\n",
    "L = Activation('softmax')(L)\n",
    "model = Model(inputs = inputs, outputs = L)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # (512, 600)\n",
    "# # 0 black\n",
    "# # 1 red\n",
    "# # 2 blue\n",
    "# # 3 purple\n",
    "# # 4 lime\n",
    "# # 5 orange\n",
    "# # 6 yellow\n",
    "# # 7 magenta\n",
    "# # magenta\n",
    "\n",
    "# print(manual_labels[train_indices[37]][127,:,:]) # The manual label that was done by Columbia\n",
    "# for i in range(8):\n",
    "#     print(i)\n",
    "#     print(train_labels[37,120,:,i]) # the trained_label I return/\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,2))\n",
    "plt.imshow(np.rot90(train_images[37,:,:,0]), cmap=plt.cm.gray)\n",
    "plt.suptitle(filenames[train_indices[37]], size=15)\n",
    "\n",
    "# print(train_indices[37])\n",
    "plt.figure(figsize=(15,2))\n",
    "plt.imshow(np.rot90(manual_labels[train_indices[37]]))\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(15,2))\n",
    "# plt.imshow(np.rot90(np.reshape(sample_weights[37], (512,64)) ))\n",
    "\n",
    "# # All the labels on top of each other\n",
    "# plt.figure(figsize=(15,2))\n",
    "# for i in range(7):\n",
    "#     plt.imshow(np.rot90(train_labels[37,:,:,i]), alpha=0.2)\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=7, ncols=1, figsize=(15,20))\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.imshow(np.rot90(train_labels[37,:,:,i]))\n",
    "#     ax.set_title(\"slice \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for j in range(3):\n",
    "#     plt.figure(figsize=(15,2))\n",
    "#     plt.imshow(np.rot90(train_images[j,:,:,0]), cmap=plt.cm.gray)\n",
    "#     plt.suptitle(filenames[train_indices[j]], size=15)\n",
    "    \n",
    "#     print(train_indices[j])\n",
    "#     plt.figure(figsize=(15,2))\n",
    "#     plt.imshow(np.rot90(manual_labels[train_indices[j]]))\n",
    "\n",
    "#     plt.figure(figsize=(15,2))\n",
    "#     plt.imshow(np.rot90(np.reshape(sample_weights[j], (512,64)) ))\n",
    "\n",
    "#     # All the labels on top of each other\n",
    "#     plt.figure(figsize=(15,2))\n",
    "#     for i in range(8):\n",
    "#         plt.imshow(np.rot90(train_labels[j,:,:,i]), alpha=0.2)\n",
    "\n",
    "#     fig, axes = plt.subplots(nrows=8, ncols=1, figsize=(15,20))\n",
    "#     for i, ax in enumerate(axes):\n",
    "#         ax.imshow(np.rot90(train_labels[j,:,:,i]))\n",
    "#         ax.set_title(\"slice \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=7, ncols=1, figsize=(20,20))\n",
    "# for i, ax in enumerate(axes):\n",
    "#     ax.imshow(np.rot90(train_labels[0,:,:,i]))\n",
    "#     ax.set_title(\"slice \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first value is number of images\n",
    "print(len(train_images))\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.reshape(train_labels,(validation_cutoff,data_shape,8))\n",
    "test_labels = np.reshape(test_labels,(num_files-validation_cutoff,data_shape,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.zeros(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.sum(train_labels==1,axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# His are floats\n",
    "new_count = np.zeros(8)\n",
    "for i in range(8):\n",
    "    new_count[i] = float(count[i])\n",
    "#     print(new_count[i])\n",
    "count = new_count\n",
    "for i in range(8):\n",
    "    print(count[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = np.median(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale = np.zeros(8)\n",
    "# for i in range(8):\n",
    "#     scale[i] = (median/count[i])\n",
    "# scale.min()\n",
    "# weights = np.zeros(8)\n",
    "# for i in range(8):\n",
    "#     weights[i] = scale[i]/scale.min()\n",
    "# print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    '''\n",
    "    y_true = label\n",
    "    y_pred = prediction\n",
    "    '''\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_loss(y_true,y_pred):\n",
    "    cross_ent = K.categorical_crossentropy(y_true, y_pred)\n",
    "    loss_dice_coef = dice_coef_loss(y_true, y_pred)\n",
    "    return (1 * cross_ent)+(0.5*loss_dice_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = np.array(train_labels_random)\n",
    "# np.random.shuffle(k)\n",
    "# k = k.reshape((k.shape[0], k.shape[1]*k.shape[2], k.shape[3]))\n",
    "# print(k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = tf.convert_to_tensor(k, dtype=np.float64)\n",
    "# l = tf.convert_to_tensor(train_labels, dtype=np.float64)\n",
    "# print(l)\n",
    "# s = customized_loss(l[0], k[0])\n",
    "# np.max(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(l[0])\n",
    "# print(k[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = K.categorical_crossentropy(l[0], k[0])\n",
    "# init_g = tf.global_variables_initializer()\n",
    "# init_l = tf.local_variables_initializer()\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init_g)\n",
    "#     sess.run(init_l)\n",
    "#     el = l[0].eval(session=sess)\n",
    "#     kel = k[0].eval(session=sess)\n",
    "#     dice_coef = dice_coef_loss(l[0], k[0]).eval(session=sess)\n",
    "#     cross_ent = K.categorical_crossentropy(l[0], k[0]).eval(session=sess)\n",
    "#     sim=s.eval(session=sess)\n",
    "# print(el.shape,el.max(),el.min(), np.unique(el)) # they're encoded correctly and have only values 0 to 1\n",
    "# print(kel.shape,kel.max(),kel.min(), np.unique(kel))\n",
    "# print(dice_coef)\n",
    "# print(cross_ent.shape,cross_ent)\n",
    "# print(sim.shape, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(train_images[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lrs = [0.01, 0.02, 0.025, 0.03, 0.04]\n",
    "# lrs = [0.01]\n",
    "# # optimiser = optimizers.Adam(lr = 0.01)\n",
    "# for i in lrs:\n",
    "#     optimiser = optimizers.Adam(lr = i)\n",
    "#     model.compile(optimizer=optimiser,loss=customized_loss,metrics=['accuracy',dice_coef],sample_weight_mode='temporal')\n",
    "    \n",
    "#     #Defining Callback functions which will be called by model during runtime when specified condition satisfies\n",
    "#     saved_name = \"layered_segments_normal_bs20_epochs20_lr\"+str(i).replace('.','_')\n",
    "#     lr_reducer = ReduceLROnPlateau(factor=0.5, cooldown=0, patience=6, min_lr=0.5e-6)\n",
    "#     csv_logger = CSVLogger(saved_name+'.csv')\n",
    "#     model_chekpoint = ModelCheckpoint(saved_name+\".hdf5\",monitor = 'val_loss',verbose = 1,save_best_only=True)\n",
    "#     print('================'+str(i)+'===================')\n",
    "#     model.fit(train_images,train_labels,batch_size=20,epochs=20,validation_data=(test_images,test_labels),sample_weight=sample_weights,callbacks=[lr_reducer, csv_logger,model_chekpoint])\n",
    "    \n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Defining Callback functions which will be called by model during runtime when specified condition satisfies\n",
    "# saved_name = \"brushlet_enhanced_bs50_epochs40_1\"\n",
    "# lr_reducer = ReduceLROnPlateau(factor=0.5, cooldown=0, patience=6, min_lr=0.5e-6)\n",
    "# csv_logger = CSVLogger(saved_name+'.csv')\n",
    "# model_chekpoint = ModelCheckpoint(saved_name+\".hdf5\",monitor = 'val_loss',verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val = 150\n",
    "# train_images = train_images[:val]\n",
    "# train_labels = train_labels[:val]\n",
    "# test_images = test_images\n",
    "# test_labels = test_labels\n",
    "# sample_weights = sample_weights[:val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(train_images,train_labels,batch_size=20,epochs=2,validation_data=(test_images,test_labels),sample_weight=sample_weights,callbacks=[lr_reducer, csv_logger,model_chekpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"/home/sim/notebooks/relaynet_pytorch/\"+saved_name+\".hdf5\")\n",
    "saved_name = 'layered_segments_normal_bs20_epochs200_01'\n",
    "model.load_weights(\"/home/sim/notebooks/relaynet_pytorch/models/Trained_Networks/\"+saved_name+\".hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15,16):\n",
    "    ind = i\n",
    "    \n",
    "    # Raw Test Image \n",
    "    testing_image = train_images[ind]\n",
    "    testing_image = np.squeeze(testing_image,axis = 2)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(np.rot90(testing_image), cmap=plt.cm.gray)\n",
    "    \n",
    "    # Manual Test Image \n",
    "    plt.figure(figsize=(15,2))\n",
    "    plt.imshow(np.rot90(manual_labels[train_indices[37]]))\n",
    "\n",
    "#     plt.figure(figsize=(20,10))\n",
    "#     new_train_labels = np.copy(train_labels)\n",
    "#     new_train_labels = new_train_labels.reshape((validation_cutoff,512,64,8))\n",
    "#     for i in range(7):\n",
    "#         plt.imshow(np.rot90(new_train_labels[ind,:,:,i]), alpha=0.5)\n",
    "    \n",
    "#     fig, axes = plt.subplots(nrows=1, ncols=7, figsize=(10,10))\n",
    "#     for i, ax in enumerate(axes):\n",
    "#         ax.imshow(np.rot90(new_train_labels[ind,:,:,i]))\n",
    "#         ax.set_title(\"slice \" + str(i))\n",
    "    plt.show()\n",
    "\n",
    "    testing_image = testing_image.reshape((1,512,64,1))\n",
    "    prediction = model.predict(testing_image)\n",
    "    prediction = np.squeeze(prediction,axis = 0)\n",
    "#     print(prediction.shape)\n",
    "\n",
    "    np.argmax(prediction[6999])\n",
    "\n",
    "    prediction = np.reshape(prediction,(512,64,8))\n",
    "    output = np.zeros((512,64))\n",
    "    ground = np.zeros((512,64))\n",
    "    for i in range(512):\n",
    "        for j in range(64):\n",
    "            index = np.argmax(prediction[i][j])\n",
    "            output[i][j] = index\n",
    "    test_labels[0].shape\n",
    "\n",
    "    # test_labels[20][6999]\n",
    "\n",
    "    test_ground_truth = np.reshape(train_labels[ind],(512,64,8))\n",
    "    for i in range(512):\n",
    "        for j in range(64):\n",
    "            index = np.argmax(test_ground_truth[i][j])\n",
    "            ground[i][j] = index\n",
    "    for i in range(512):\n",
    "        for j in range(64):\n",
    "            index = np.argmax(prediction[i][j])\n",
    "            output[i][j] = index\n",
    "#     print (output.shape)\n",
    "\n",
    "    color= np.zeros((512,64,3))\n",
    "    c0 = 0\n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "    c3 = 0\n",
    "    c4 = 0\n",
    "    c5 = 0\n",
    "    c6 = 0\n",
    "    c7 = 0\n",
    "    for j in range(512):\n",
    "        for k in range(64):\n",
    "            if(output[j][k]==0):\n",
    "                c0 = c0 + 1\n",
    "                color[j][k] = [0,0,0]\n",
    "            if(output[j][k]==1):\n",
    "                c1 = c1 + 1\n",
    "                color[j][k] = [255,0,0]\n",
    "            if(output[j][k]==2):\n",
    "                c2 = c2 + 1\n",
    "                color[j][k] = [0, 0, 255]\n",
    "            if(output[j][k]==3):\n",
    "                c3 = c3 + 1\n",
    "                color[j][k] = [177,10,255] \n",
    "            if(output[j][k]==4):\n",
    "                c4 = c4 + 1\n",
    "                color[j][k] = [0,255,0]\n",
    "            if(output[j][k]==5):\n",
    "                c5 = c5 + 1\n",
    "                color[j][k] = [255, 140, 0]\n",
    "            if(output[j][k]==6):\n",
    "                c6 = c6 + 1\n",
    "                color[j][k] = [255, 255, 0]\n",
    "            if(output[j][k]==7):\n",
    "                c7 = c7 + 1\n",
    "                color[j][k] = [255,0,255]\n",
    "\n",
    "#     print('index 0:', c0)\n",
    "#     print('index 1:', c1)\n",
    "#     print('index 2:', c2)\n",
    "#     print('index 3:', c3)\n",
    "#     print('index 4:', c4)\n",
    "#     print('index 5:', c5)\n",
    "#     print('index 6:', c6)\n",
    "#     print('index 7:', c7)\n",
    "\n",
    "    %matplotlib inline\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(np.rot90(color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
